{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "from annoy import AnnoyIndex\n",
    "import os\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug=False\n",
    "doTest=False\n",
    "bucketSize=20\n",
    "minValueOfNrHitsForParticleWithMostHits=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pt orice proiect fisier de input din care sa iau date si fisier de output in care sa pun rezultatul obtinut\n",
    "inputFolderName=\"/Users/luizaadelinaciucu/Work/ATLAS/data/TrackML/ttbar_mu200-generic\"\n",
    "outputFolderName=\"/Users/luizaadelinaciucu/Work/ATLAS/TrackML/output_min5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eventNumber_from_fileName(fileName):\n",
    "    eventNumber=fileName.replace(\"event\",\"\").replace(\"-hits.csv\",\"\")\n",
    "    return eventNumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All events available in my folder. list_eventNumber ['000000000', '000000001', '000000002', '000000003', '000000004', '000000005', '000000006', '000000007', '000000008', '000000009', '000000010', '000000011', '000000012', '000000013', '000000014', '000000015', '000000016', '000000017', '000000018', '000000019', '000000020', '000000021', '000000022', '000000023', '000000024', '000000025', '000000026', '000000027', '000000028', '000000029', '000000030', '000000031', '000000032', '000000033', '000000034', '000000035', '000000036', '000000037', '000000038', '000000039', '000000040', '000000041', '000000042', '000000043', '000000044', '000000045', '000000046', '000000047', '000000048', '000000049', '000000050', '000000051', '000000052', '000000053', '000000054', '000000055', '000000056', '000000057', '000000058', '000000059', '000000060', '000000061', '000000062', '000000063', '000000064', '000000065', '000000066', '000000067', '000000068', '000000069', '000000070', '000000071', '000000072', '000000073', '000000074', '000000075', '000000076', '000000077', '000000078', '000000079', '000000080', '000000081', '000000082', '000000083', '000000084', '000000085', '000000086', '000000087', '000000088', '000000089', '000000090', '000000091', '000000092', '000000093', '000000094', '000000095', '000000096', '000000097', '000000098', '000000099']\n"
     ]
    }
   ],
   "source": [
    "# calculate event numbers from my folder\n",
    "# lista goala in care sa pun numerele evenimentelor\n",
    "list_eventNumber=[]\n",
    "# The sorted() function returns a sorted list of the specified iterable object \n",
    "# Strings are sorted alphabetically, and numbers are sorted numerically\n",
    "# os operating system \n",
    "# hits ca sa nu am de doura ori evenimentul in lista\n",
    "for fileName in sorted(os.listdir(inputFolderName)):\n",
    "    if fileName.endswith(\"-hits.csv\"):\n",
    "        #print(fileName)\n",
    "        eventNumber=get_eventNumber_from_fileName(fileName)\n",
    "        #print(eventNumber)\n",
    "        list_eventNumber.append(eventNumber)\n",
    "# done for loop\n",
    "#list_eventNumber=[\"000000007\",\"000000008\"]\n",
    "print(\"All events available in my folder. list_eventNumber\", list_eventNumber)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this runs only once per event\n",
    "def buildAnnoyIndex(nparray_position,metric=\"angular\",ntrees=10,debug=False): \n",
    "    \n",
    "    numberDimension=nparray_position.shape[1] # 3 (x,y,z)\n",
    "    if debug:\n",
    "        print(\"numberDimension\",numberDimension,\"metric\",metric)\n",
    "    index=AnnoyIndex(numberDimension,metric)\n",
    "    if debug:\n",
    "        print(\"type(index)\",type(index))\n",
    "        print(\"enumerate data\")\n",
    "    # add each hit to the index\n",
    "    for i,position in enumerate(nparray_position):\n",
    "        if debug:\n",
    "            print(\"i\",i,\"position\",position)\n",
    "        index.add_item(i,position)\n",
    "    # done for loop over hits\n",
    "    # build the index with 10 trees\n",
    "    index.build(ntrees) # 10 trees\n",
    "    return index\n",
    "# done function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_output_from_df_hits(df_hits,index):\n",
    "    list_nparray_input=[]\n",
    "    list_nparray_output=[]\n",
    "    \n",
    "    nparray_volume_id=df_hits[\"volume_id\"].values\n",
    "    nparray_layer_id=df_hits[\"layer_id\"].values\n",
    "    \n",
    "    counterHitForBucket=0\n",
    "    counterBucket=0\n",
    "    \n",
    "    for i in range(len(df_hits)):\n",
    "        if (\n",
    "            (nparray_volume_id[i]==8 and nparray_layer_id[i]==2) \n",
    "            #or (nparray_volume_id[i]==7 and nparray_layer_id[i]==2)\n",
    "            #or (nparray_volume_id[i]==9 and nparray_layer_id[i]==14)\n",
    "            #or (nparray_volume_id[i]==16 and nparray_layer_id[i]==2)\n",
    "            #or (nparray_volume_id[i]==12 and nparray_layer_id[i]==2)\n",
    "            #or (nparray_volume_id[i]==18 and nparray_layer_id[i]==12)\n",
    "            #or (nparray_volume_id[i]==14 and nparray_layer_id[i]==12)\n",
    "            #or (nparray_volume_id[i]==17 and nparray_layer_id[i]==4)\n",
    "            )==False:\n",
    "            continue\n",
    "\n",
    "        counterHitForBucket+=1\n",
    "        \n",
    "        #if (counterHitForBucket%3==1)==False:\n",
    "            #continue\n",
    "            \n",
    "        counterBucket+=1\n",
    "        \n",
    "        if debug:\n",
    "            print(\"i\",i,\"counterHitForBucket\",counterHitForBucket,\"counterBucket\",counterBucket)\n",
    "            \n",
    "        # using annoy to find the 20 nearest neighboring hits by angle to this hit\n",
    "        list_index=index.get_nns_by_item(i,bucketSize)\n",
    "        if debug:\n",
    "            print(\"list_index\",list_index)\n",
    "            \n",
    "        # create bucket\n",
    "        df_bucket=df_hits.iloc[list_index]\n",
    "        \n",
    "        # create NN input for this one bucket\n",
    "        nparray_input=df_bucket[[\"x\",\"y\",\"z\"]].values.flatten()\n",
    "        if debug:\n",
    "            print(\"nparray_input\",nparray_input,\"shape\",nparray_input.shape,\"type\",type(nparray_input))\n",
    "            \n",
    "        # create NN output for this one bucket\n",
    "        # identify particle with the largest number of hits in this bucket\n",
    "        nparray_particleID=df_bucket[\"particle_id\"].values\n",
    "\n",
    "        if debug:\n",
    "            print(\"nparray_particleID\",nparray_particleID,\"shape\",nparray_particleID.shape,\"type\",type(nparray_particleID))\n",
    "        dict_particleID_counterParticleID={}\n",
    "        for particleID in nparray_particleID:\n",
    "            if particleID not in dict_particleID_counterParticleID:\n",
    "                dict_particleID_counterParticleID[particleID]=1\n",
    "            else:\n",
    "                dict_particleID_counterParticleID[particleID]+=1\n",
    "        if debug:\n",
    "            print(\"dict_particleID_counterParticleID\",dict_particleID_counterParticleID)\n",
    "          \n",
    "        # find the maximum value of the counters\n",
    "        particleIDWithMaxHits=0\n",
    "        counterParticleIDWithMaxHits=0\n",
    "        for particleID in dict_particleID_counterParticleID:\n",
    "            counterParticleID=dict_particleID_counterParticleID[particleID]\n",
    "            if counterParticleID>counterParticleIDWithMaxHits:\n",
    "                counterParticleIDWithMaxHits=counterParticleID\n",
    "                particleIDWithMaxHits=particleID\n",
    "        if debug:\n",
    "            print(\"counterBucket\",counterBucket,\"particleIDWithMaxHits\",particleIDWithMaxHits,\"counterParticleIDWithMaxHits\",counterParticleIDWithMaxHits)        \n",
    "        \n",
    "        # create nparray_output\n",
    "        list_output=[]\n",
    "        \n",
    "        # loop over every hit in the bucket\n",
    "        for particleID in nparray_particleID:      \n",
    "            if counterParticleIDWithMaxHits<minValueOfNrHitsForParticleWithMostHits:\n",
    "                list_output.append(-1)\n",
    "            else:\n",
    "                # do normally\n",
    "                if particleID==particleIDWithMaxHits:\n",
    "                    list_output.append(1)\n",
    "                else:\n",
    "                    list_output.append(-1)\n",
    "                # done if\n",
    "            # done if\n",
    "        # done for loop for each hit in the bucket\n",
    "        if debug:        \n",
    "            print(\"list_output\",list_output)\n",
    "        nparray_output=np.array(list_output)\n",
    "        if debug:\n",
    "            print(\"nparray_output\",nparray_output)\n",
    "            \n",
    "        if debug and doTest:\n",
    "            print(\"i\",i,\"counterBucket\",counterBucket)\n",
    "            plt.plot(df_bucket.x,df_bucket.y,\"o\",color=\"red\")\n",
    "            plt.plot(0,0,\"r+\")\n",
    "            plt.title(str(i))\n",
    "            plt.show()\n",
    "            plotBucketFileNameStem=outputFolderName+\"/bucket_i_\"+str(i)+\"_counterBucket_\"+str(counterBucket)+\"_eventNumber_\"+eventNumber\n",
    "            # plt.savefig(plotBucketFileNameStem+\".png\")\n",
    "            # plt.savefig(plotBucketFileNameStem+\".pdf\")\n",
    "        # done if\n",
    "            \n",
    "        # add for this current bucket to the list for the entire event (which has several buckets)\n",
    "        list_nparray_input.append(nparray_input)\n",
    "        list_nparray_output.append(nparray_output)\n",
    "    # done for loop over hits in the event\n",
    "    \n",
    "    # transform list of numpy array into numpy array of dimension 2 \n",
    "    # rows are buckets, columns are intput and output values\n",
    "    nparray_input_all=np.array(list_nparray_input)\n",
    "    nparray_output_all=np.array(list_nparray_output)\n",
    "    \n",
    "    return nparray_input_all, nparray_output_all\n",
    "# done function      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i 0 eventNumber 000000000\n",
      "i 1 eventNumber 000000001\n",
      "i 2 eventNumber 000000002\n",
      "i 3 eventNumber 000000003\n",
      "i 4 eventNumber 000000004\n",
      "i 5 eventNumber 000000005\n",
      "i 6 eventNumber 000000006\n",
      "i 7 eventNumber 000000007\n",
      "i 8 eventNumber 000000008\n",
      "i 9 eventNumber 000000009\n",
      "nparray_Input_Train_all_Events [[[  -32.3306 ]\n",
      "  [   -4.28872]\n",
      "  [ -462.092  ]\n",
      "  ...\n",
      "  [  -89.3    ]\n",
      "  [  -15.1782 ]\n",
      "  [-1302.5    ]]\n",
      "\n",
      " [[  -30.0484 ]\n",
      "  [  -10.8162 ]\n",
      "  [ -427.981  ]\n",
      "  ...\n",
      "  [  -47.7968 ]\n",
      "  [  -14.5214 ]\n",
      "  [ -702.     ]]\n",
      "\n",
      " [[  -30.4775 ]\n",
      "  [   -9.58902]\n",
      "  [ -421.256  ]\n",
      "  ...\n",
      "  [ -112.212  ]\n",
      "  [  -40.1146 ]\n",
      "  [-1498.     ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[  -31.0392 ]\n",
      "  [    7.97939]\n",
      "  [  451.233  ]\n",
      "  ...\n",
      "  [  -57.8866 ]\n",
      "  [   16.1856 ]\n",
      "  [  822.     ]]\n",
      "\n",
      " [[  -30.7311 ]\n",
      "  [   13.4412 ]\n",
      "  [  445.29   ]\n",
      "  ...\n",
      "  [  -84.0347 ]\n",
      "  [   39.9226 ]\n",
      "  [ 1298.     ]]\n",
      "\n",
      " [[  -30.6693 ]\n",
      "  [   14.5378 ]\n",
      "  [  462.772  ]\n",
      "  ...\n",
      "  [  -61.4119 ]\n",
      "  [   29.2769 ]\n",
      "  [  962.5    ]]] shape (74955, 60, 1) type <class 'numpy.ndarray'>\n",
      "nparray_Input_Test_all_Events [[[-3.27351e+01]\n",
      "  [-3.13191e+00]\n",
      "  [-4.42867e+02]\n",
      "  ...\n",
      "  [-4.44534e+01]\n",
      "  [-1.76822e+00]\n",
      "  [-6.02500e+02]]\n",
      "\n",
      " [[-3.72866e+01]\n",
      "  [-1.21141e+01]\n",
      "  [-5.98000e+02]\n",
      "  ...\n",
      "  [-4.40492e+01]\n",
      "  [-1.35834e+01]\n",
      "  [-6.98000e+02]]\n",
      "\n",
      " [[-3.05373e+01]\n",
      "  [-9.41792e+00]\n",
      "  [-4.80159e+02]\n",
      "  ...\n",
      "  [-4.29130e+01]\n",
      "  [-1.39791e+01]\n",
      "  [-6.98000e+02]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-3.11283e+01]\n",
      "  [ 6.40070e+00]\n",
      "  [ 4.25920e+02]\n",
      "  ...\n",
      "  [-4.50531e+01]\n",
      "  [ 5.27609e+00]\n",
      "  [ 5.97500e+02]]\n",
      "\n",
      " [[-3.11983e+01]\n",
      "  [ 5.15883e+00]\n",
      "  [ 4.80590e+02]\n",
      "  ...\n",
      "  [-8.26056e+01]\n",
      "  [ 1.36984e+01]\n",
      "  [ 1.29750e+03]]\n",
      "\n",
      " [[-3.15253e+01]\n",
      "  [-6.38107e-01]\n",
      "  [ 4.84435e+02]\n",
      "  ...\n",
      "  [-9.04663e+01]\n",
      "  [ 1.07622e+00]\n",
      "  [ 1.29750e+03]]] shape (32392, 60, 1) type <class 'numpy.ndarray'>\n",
      "nparray_Output_Train_all_Events [[-1  1 -1 ... -1 -1 -1]\n",
      " [ 1 -1 -1 ... -1 -1 -1]\n",
      " [-1 -1 -1 ... -1 -1 -1]\n",
      " ...\n",
      " [ 1  1  1 ... -1 -1 -1]\n",
      " [-1 -1 -1 ...  1  1  1]\n",
      " [ 1  1  1 ... -1 -1 -1]] shape (74955, 20) type <class 'numpy.ndarray'>\n",
      "nparray_Output_Test_all_Events [[-1 -1 -1 ... -1 -1 -1]\n",
      " [-1 -1 -1 ...  1  1  1]\n",
      " [ 1  1  1 ... -1 -1 -1]\n",
      " ...\n",
      " [-1 -1 -1 ... -1 -1 -1]\n",
      " [ 1  1  1 ... -1  1  1]\n",
      " [ 1  1  1 ... -1 -1 -1]] shape (32392, 20) type <class 'numpy.ndarray'>\n",
      "Done all!\n"
     ]
    }
   ],
   "source": [
    "counter_event_Train=0\n",
    "counter_event_Test=0\n",
    "# for loop over eventNumber from list_eventNumber\n",
    "for i,eventNumber in enumerate(list_eventNumber):\n",
    "    if i>9:\n",
    "        continue\n",
    "    print(\"i\",i,\"eventNumber\",eventNumber)\n",
    "    \n",
    "    inputFileName_hits_recon=inputFolderName+\"/event\"+eventNumber+\"-hits.csv\"\n",
    "    inputFileName_hits_truth=inputFolderName+\"/event\"+eventNumber+\"-truth.csv\"\n",
    "    \n",
    "    df_hits_recon=pd.read_csv(inputFileName_hits_recon)\n",
    "    df_hits_truth=pd.read_csv(inputFileName_hits_truth)\n",
    "    df_hits=pd.concat([df_hits_recon,df_hits_truth],axis=1,sort=False)\n",
    "    \n",
    "    # build annoy index\n",
    "    nparray_position=df_hits[[\"x\",\"y\",\"z\"]].values\n",
    "    if debug:\n",
    "        print(\"nparray_position\",nparray_position)\n",
    "\n",
    "    index=buildAnnoyIndex(nparray_position,metric=\"angular\",ntrees=10,debug=False)\n",
    "    \n",
    "    # for loop peste hituri peste hiturile preselectate volume_id=8, layer_id=2\n",
    "    nparray_input_all,nparray_output_all=get_input_output_from_df_hits(df_hits,index)\n",
    "    if debug:\n",
    "        print(\"nparray_input_all\",nparray_input_all,\"shape\",nparray_input_all.shape,\"type\",type(nparray_input_all)) \n",
    "        print(\"nparray_output_all\",nparray_output_all,\"shape\",nparray_output_all.shape,\"type\",type(nparray_output_all))\n",
    "    \n",
    "    # reshape only input by adding one extra dimension needed by tensorflow, in practice it puts all into one extra bracket\n",
    "    nparray_input_all=nparray_input_all.reshape(nparray_input_all.shape[0],nparray_input_all.shape[1],1)\n",
    "    if debug:\n",
    "        print(\"nparray_input_all\",nparray_input_all,\"shape\",nparray_input_all.shape,\"type\",type(nparray_input_all))\n",
    "\n",
    "    # calcualte the rest of the event index to division by 10\n",
    "\n",
    "    if doTest:\n",
    "        # use two events, one in train, one in test\n",
    "        nbDenominator=2\n",
    "        maxRestForTrain=0\n",
    "    else:\n",
    "        # running fully\n",
    "        #nbDenominator=100\n",
    "        #maxRestForTrain=69\n",
    "        nbDenominator=10\n",
    "        maxRestForTrain=6\n",
    "    # done if\n",
    "    rest=i%nbDenominator\n",
    "    if rest<=maxRestForTrain: \n",
    "        # put this event into Train: rest=0,1,2,3,4,5,6\n",
    "        counter_event_Train+=1\n",
    "        if counter_event_Train==1:\n",
    "            # it is the first event of type Train, so we simply deep copy it to the output\n",
    "            nparray_Input_Train_all_Events=copy.deepcopy(nparray_input_all)\n",
    "            nparray_Output_Train_all_Events=copy.deepcopy(nparray_output_all)\n",
    "        else:\n",
    "            # it is not the first, so we concatentane to the new output\n",
    "            nparray_Input_Train_all_Events=np.concatenate((nparray_Input_Train_all_Events,nparray_input_all),axis=0,out=None)\n",
    "            nparray_Output_Train_all_Events=np.concatenate((nparray_Output_Train_all_Events,nparray_output_all),axis=0,out=None)\n",
    "        # done if\n",
    "    else:\n",
    "        # put this event into Test: rest=7,8,9\n",
    "        counter_event_Test+=1\n",
    "        if counter_event_Test==1:\n",
    "            # it is the first event of type Test, so we simply deep copy it to the output\n",
    "            nparray_Input_Test_all_Events=copy.deepcopy(nparray_input_all)\n",
    "            nparray_Output_Test_all_Events=copy.deepcopy(nparray_output_all)\n",
    "        else:\n",
    "            # it is not the first, so we concatentane to the new output\n",
    "            nparray_Input_Test_all_Events=np.concatenate((nparray_Input_Test_all_Events,nparray_input_all),axis=0,out=None)\n",
    "            nparray_Output_Test_all_Events=np.concatenate((nparray_Output_Test_all_Events,nparray_output_all),axis=0,out=None)\n",
    "        # done if\n",
    "    # done if\n",
    "# done for loop over eventNumber\n",
    "\n",
    "eventNumber=\"all\"\n",
    "fileNameNNInputTrainAll=outputFolderName+\"/NN_2_data_Input_Train_\"+eventNumber+\".npy\"\n",
    "fileNameNNInputTestAll=outputFolderName+\"/NN_2_data_Input_Test_\"+eventNumber+\".npy\"\n",
    "fileNameNNOutputTrainAll=outputFolderName+\"/NN_2_data_Output_Train_\"+eventNumber+\".npy\"\n",
    "fileNameNNOutputTestAll=outputFolderName+\"/NN_2_data_Output_Test_\"+eventNumber+\".npy\"\n",
    "\n",
    "np.save(fileNameNNInputTrainAll,nparray_Input_Train_all_Events)\n",
    "np.save(fileNameNNOutputTrainAll,nparray_Output_Train_all_Events)\n",
    "np.save(fileNameNNInputTestAll,nparray_Input_Test_all_Events)\n",
    "np.save(fileNameNNOutputTestAll,nparray_Output_Test_all_Events)\n",
    "\n",
    "print(\"nparray_Input_Train_all_Events\",nparray_Input_Train_all_Events,\"shape\",nparray_Input_Train_all_Events.shape,\"type\",type(nparray_Input_Train_all_Events))\n",
    "print(\"nparray_Input_Test_all_Events\",nparray_Input_Test_all_Events,\"shape\",nparray_Input_Test_all_Events.shape,\"type\",type(nparray_Input_Test_all_Events))\n",
    "print(\"nparray_Output_Train_all_Events\",nparray_Output_Train_all_Events,\"shape\",nparray_Output_Train_all_Events.shape,\"type\",type(nparray_Output_Train_all_Events))\n",
    "print(\"nparray_Output_Test_all_Events\",nparray_Output_Test_all_Events,\"shape\",nparray_Output_Test_all_Events.shape,\"type\",type(nparray_Output_Test_all_Events))\n",
    "\n",
    "print(\"Done all!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nparray_Input_Train_all_Events [[[  -32.3306 ]\n",
      "  [   -4.28872]\n",
      "  [ -462.092  ]\n",
      "  ...\n",
      "  [  -89.3    ]\n",
      "  [  -15.1782 ]\n",
      "  [-1302.5    ]]\n",
      "\n",
      " [[  -30.0484 ]\n",
      "  [  -10.8162 ]\n",
      "  [ -427.981  ]\n",
      "  ...\n",
      "  [  -47.7968 ]\n",
      "  [  -14.5214 ]\n",
      "  [ -702.     ]]\n",
      "\n",
      " [[  -30.4775 ]\n",
      "  [   -9.58902]\n",
      "  [ -421.256  ]\n",
      "  ...\n",
      "  [ -112.212  ]\n",
      "  [  -40.1146 ]\n",
      "  [-1498.     ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[  -31.0392 ]\n",
      "  [    7.97939]\n",
      "  [  451.233  ]\n",
      "  ...\n",
      "  [  -57.8866 ]\n",
      "  [   16.1856 ]\n",
      "  [  822.     ]]\n",
      "\n",
      " [[  -30.7311 ]\n",
      "  [   13.4412 ]\n",
      "  [  445.29   ]\n",
      "  ...\n",
      "  [  -84.0347 ]\n",
      "  [   39.9226 ]\n",
      "  [ 1298.     ]]\n",
      "\n",
      " [[  -30.6693 ]\n",
      "  [   14.5378 ]\n",
      "  [  462.772  ]\n",
      "  ...\n",
      "  [  -61.4119 ]\n",
      "  [   29.2769 ]\n",
      "  [  962.5    ]]] shape (74955, 60, 1) type float64\n"
     ]
    }
   ],
   "source": [
    "print(\"nparray_Input_Train_all_Events\",nparray_Input_Train_all_Events,\"shape\",nparray_Input_Train_all_Events.shape,\"type\",nparray_Input_Train_all_Events.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nparray_Output_Train_all_Events [[-1  1 -1 ... -1 -1 -1]\n",
      " [ 1 -1 -1 ... -1 -1 -1]\n",
      " [-1 -1 -1 ... -1 -1 -1]\n",
      " ...\n",
      " [ 1  1  1 ... -1 -1 -1]\n",
      " [-1 -1 -1 ...  1  1  1]\n",
      " [ 1  1  1 ... -1 -1 -1]] shape (74955, 20) type int64\n"
     ]
    }
   ],
   "source": [
    "print(\"nparray_Output_Train_all_Events\",nparray_Output_Train_all_Events,\"shape\",nparray_Output_Train_all_Events.shape,\"type\",nparray_Output_Train_all_Events.dtype)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
