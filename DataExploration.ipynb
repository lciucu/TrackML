{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputFolderName=\"/Users/luizaadelinaciucu/Work/ATLAS/TrackML/input/ttbar_mu200-generic\"\n",
    "inputFolderName=\"/Volumes/Luiza_SSD/ATLAS/TrackML/data/ttbar_mu200-generic\"\n",
    "outputFolderName=\"/Volumes/Luiza_SSD/ATLAS/TrackML/plots_data_exploration\"\n",
    "#\n",
    "eventNumber=\"000000099\"\n",
    "#\n",
    "inputFileName_hits_recon=inputFolderName+\"/event\"+eventNumber+\"-hits.csv\"\n",
    "inputFileName_hits_truth=inputFolderName+\"/event\"+eventNumber+\"-truth.csv\"\n",
    "#\n",
    "list_extension=[\n",
    "    \"png\",\n",
    "    \"pdf\",\n",
    "]\n",
    "# if output folder does not exist, create it\n",
    "if not os.path.exists(outputFolderName):\n",
    "    os.makedirs(outputFolderName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hits_recon=pd.read_csv(inputFileName_hits_recon)\n",
    "df_hits_recon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hits_truth=pd.read_csv(inputFileName_hits_truth)\n",
    "df_hits_truth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine truth and recon\n",
    "\n",
    "df_hits=pd.concat([df_hits_recon,df_hits_truth],axis=1,sort=False)\n",
    "df_hits.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter=0\n",
    "n=df_hits[\"volume_id\"].values\n",
    "for value in n:\n",
    "    if value==9:\n",
    "        counter+=1\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter=0\n",
    "m=df_hits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist(df_hits[\"x\"],bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_hits[\"y\"],bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_hits[\"z\"],bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_hits[\"volume_id\"],bins=range(0,21,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_hits[\"layer_id\"],bins=range(0,21,1))\n",
    "df_hits[\"layer_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_hits[\"module_id\"],bins=range(0,1000,1))   #bins=100)\n",
    "df_hits[\"module_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_hits[\"volume_id\"],np.sqrt(df_hits[\"x\"]**2+df_hits[\"y\"]**2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_hits[\"volume_id\"],df_hits[\"z\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_hits[\"layer_id\"],np.sqrt(df_hits[\"x\"]**2+df_hits[\"y\"]**2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_hits[\"layer_id\"],df_hits[\"z\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_hits[\"module_id\"],np.sqrt(df_hits[\"x\"]**2+df_hits[\"y\"]**2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_hits[\"module_id\"],df_hits[\"z\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_hits[\"z\"],np.sqrt(df_hits[\"x\"]**2+df_hits[\"y\"]**2))\n",
    "plt.ylabel(\"radius [mm]\")\n",
    "plt.xlabel(\"z-coordinate [mm]\")\n",
    "\n",
    "for extension in list_extension:\n",
    "    plt.savefig(outputFolderName+\"/DataExploration_z_vs_r_scatter.\"+extension)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count how many hits are in each truth particle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d={}\n",
    "for i in df_hits[\"particle_id\"]:\n",
    "    if i not in d.keys():\n",
    "        d[i]=1\n",
    "    else:\n",
    "        d[i]+=1\n",
    "# done for loop \n",
    "for i in sorted(d.keys()):\n",
    "    print(\"particle_id\",i,\"counter\",d[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot the counter of hits for each particle in a histogram\n",
    "plt.hist(d.values(),bins=range(0,23,1))\n",
    "plt.xlabel(\"Number of hits in a truth particle\", fontsize=16)\n",
    "plt.ylabel(\"Count of truth particles\",fontsize=16)\n",
    "for extension in list_extension:\n",
    "    plt.savefig(outputFolderName+\"/DataExploration_histo_counterTruthParticles_vs_nbHitsInTruthParticle.\"+extension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist2d(np.sqrt(df_hits[\"x\"]**2+df_hits[\"y\"]**2),df_hits[\"volume_id\"],\n",
    "           bins=[range(30,50,1),range(8,10,1)],\n",
    "           cmin=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist2d(np.sqrt(df_hits[\"x\"]**2+df_hits[\"y\"]**2),df_hits[\"volume_id\"],\n",
    "           bins=[range(30,50,1),range(8,10,1)],\n",
    "           cmin=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Study the x, y, z interval for each `volume_id`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug=False\n",
    "list_index=[]\n",
    "nparray_layer_id=df_hits[\"layer_id\"].values\n",
    "nparray_z=df_hits[\"z\"].values\n",
    "nparray_r=np.sqrt(df_hits[\"x\"]**2+df_hits[\"y\"]**2)\n",
    "for i,val in enumerate(df_hits[\"volume_id\"].values):\n",
    "    if (True)==False:\n",
    "        continue\n",
    "    if (True)==False:\n",
    "        continue\n",
    "    #if (val==8)==False:\n",
    "    #    continue\n",
    "    #if (nparray_layer_id[i]==2)==False:\n",
    "    #    continue\n",
    "    r=nparray_r[i]\n",
    "    z=nparray_z[i]\n",
    "    if debug:\n",
    "        print(\"i\",i,\"val\",val,\"z\",z)\n",
    "    list_index.append(i)\n",
    "print(\"len\",len(list_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reduced=df_hits.iloc[list_index]\n",
    "df_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist2d(\n",
    "        df_reduced[\"z\"],np.sqrt(df_reduced[\"x\"]**2+df_reduced[\"y\"]**2),\n",
    "        bins=[range(-3000,3000,10),range(0,1050,1)],\n",
    "        cmin=10,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_reduced[\"layer_id\"],bins=range(0,10,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's find the min and max of x, y, z of hits\n",
    "# in each pair of volume_id and layer_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eventNumber_from_fileName(fileName):\n",
    "    eventNumber=fileName.replace(\"event\",\"\").replace(\"-hits.csv\",\"\")\n",
    "    return eventNumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate event numbers from my folder\n",
    "# lista goala in care sa pun numerele evenimentelor\n",
    "list_eventNumber=[]\n",
    "# The sorted() function returns a sorted list of the specified iterable object \n",
    "# Strings are sorted alphabetically, and numbers are sorted numerically\n",
    "# os operating system \n",
    "# hits ca sa nu am de doura ori evenimentul in lista\n",
    "for fileName in sorted(os.listdir(inputFolderName)):\n",
    "    if fileName.endswith(\"-hits.csv\"):\n",
    "        #print(fileName)\n",
    "        eventNumber=get_eventNumber_from_fileName(fileName)\n",
    "        #print(eventNumber)\n",
    "        list_eventNumber.append(eventNumber)\n",
    "# done for loop\n",
    "#list_eventNumber=[\"000000007\"]\n",
    "print(\"All events available in my folder. list_eventNumber\", list_eventNumber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug=False\n",
    "verbose=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_name_list_list_zrMinMax={}\n",
    "\n",
    "for i,eventNumber in enumerate(list_eventNumber):\n",
    "\n",
    "    print(\"i\",i,\"eventNumber\",eventNumber)\n",
    "    \n",
    "    inputFileName_hits_recon=inputFolderName+\"/event\"+eventNumber+\"-hits.csv\"\n",
    "    inputFileName_hits_truth=inputFolderName+\"/event\"+eventNumber+\"-truth.csv\"\n",
    "    \n",
    "    if debug or verbose:\n",
    "        print(\"Read csv files ad df and merge them\")\n",
    "    df_hits_recon=pd.read_csv(inputFileName_hits_recon)\n",
    "    df_hits_truth=pd.read_csv(inputFileName_hits_truth)\n",
    "    df_hits=pd.concat([df_hits_recon,df_hits_truth],axis=1,sort=False)\n",
    "    \n",
    "    # to free RAM memory, let's delete the data frames of recon and truth from memory\n",
    "    del df_hits_recon\n",
    "    del df_hits_truth\n",
    "\n",
    "    # \n",
    "    nparray_hit_id=df_hits[\"hit_id\"].values\n",
    "    nparray_volume_id=df_hits[\"volume_id\"].values\n",
    "    nparray_layer_id=df_hits[\"layer_id\"].values\n",
    "    nparray_x=df_hits[\"x\"].values\n",
    "    nparray_y=df_hits[\"y\"].values\n",
    "    nparray_z=df_hits[\"z\"].values\n",
    "    nparray_r=np.sqrt(nparray_x**2+nparray_y**2)\n",
    "\n",
    "    # if for each event keep only a few hits\n",
    "    max_hit_id=-1\n",
    "    for hit_id,hit_id2 in nparray_hit_id:\n",
    "        if max_hit_id>=0:\n",
    "            if hit_id > max_hit_id:\n",
    "                continue\n",
    "        if debug or hit_id%50000==0:\n",
    "            print(\"hit_id\",hit_id)\n",
    "        volume_id=nparray_volume_id[hit_id]\n",
    "        layer_id=nparray_layer_id[hit_id]\n",
    "        name=str(volume_id)+\"_\"+str(layer_id)\n",
    "        x=nparray_x[hit_id]\n",
    "        y=nparray_y[hit_id]\n",
    "        z=nparray_z[hit_id]\n",
    "        r=nparray_r[hit_id]\n",
    "        if debug:\n",
    "            print(\"volume_id\",volume_id,\"layer_id\",layer_id,\"name\",name,\"x\",x,\"y\",y,\"z\",z)\n",
    "        #\n",
    "        # calculate min and max value of z and r for each volume_id and layer_id\n",
    "        if name not in dict_name_list_list_zrMinMax.keys():\n",
    "            # name is not yet in dictionary\n",
    "            # add in dictionary with a value of a list of list\n",
    "            # z\n",
    "            # we know z varies between [-3000, 3000]\n",
    "            # first element is the starting position for min, so a large value of z, so 10000\n",
    "            # second element is the starting position for the max, so a small value of z, so -10000\n",
    "            # so to be safe we choose [-10000.0,10000.0]\n",
    "            # r\n",
    "            # we know r varies between [0, 1050]\n",
    "            # first element is the starting position for min, so a large value of z, so 2000\n",
    "            # second element is the starting position for the max, so a small value of z, so 0\n",
    "            # so to be safe we choose [2000.0,0.0]\n",
    "            dict_name_list_list_zrMinMax[name]=[[10000.0,-10000.0],[2000.0,0.0]]\n",
    "        # done if\n",
    "        # z\n",
    "        # now compare current z value with the min\n",
    "        if z<dict_name_list_list_zrMinMax[name][0][0]:\n",
    "            dict_name_list_list_zrMinMax[name][0][0]=z\n",
    "        # done if\n",
    "        # now compare current z value with the max\n",
    "        if z>dict_name_list_list_zrMinMax[name][0][1]:\n",
    "            dict_name_list_list_zrMinMax[name][0][1]=z\n",
    "        # done if\n",
    "        # r\n",
    "        # now compare current r value with the min\n",
    "        if r<dict_name_list_list_zrMinMax[name][1][0]:\n",
    "            dict_name_list_list_zrMinMax[name][1][0]=r\n",
    "        # done if\n",
    "        # now compare current r value with the max\n",
    "        if r>dict_name_list_list_zrMinMax[name][1][1]:\n",
    "            dict_name_list_list_zrMinMax[name][1][1]=r\n",
    "        # done if\n",
    "    # done for loop over hits\n",
    "# done for loop over events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    for name in dict_name_list_list_zrMinMax:\n",
    "        val=dict_name_list_list_zrMinMax[name]\n",
    "        print(\"name\",name,\"val\",val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
