{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General include statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import from basic Python to be able to read automatically the name of a file\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# import to use numpy arrays\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug=False\n",
    "verbose=True\n",
    "doTest=False\n",
    "\n",
    "doPrepareDataInputOutput=False\n",
    "doTrainNN=False\n",
    "doAnalyzeNN=True\n",
    "doPlot=True\n",
    "\n",
    "# output stem\n",
    "inputFolderName=\"/eos/user/m/msmk/data/mltracking/sim/ttbar_mu200-generic\"\n",
    "eventNumber=\"000000099\"\n",
    "outputFolderName=\"./output\"\n",
    "\n",
    "bucketSize=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a general function to print the values and other properties of a numpy array\n",
    "# use to see the values of the numpy arrays in our code for debugging and understanding the code flow\n",
    "def print_nparray(name,nparray,doForce=False):\n",
    "    if debug or doForce:\n",
    "        print(\"\")\n",
    "        print(\"nparray\",name)\n",
    "        print(nparray)\n",
    "        print(\"type\",type(nparray),\"shape\",nparray.shape,\"min_value=%.3f\"%np.min(nparray),\"min_position=%.0f\"%np.argmin(nparray),\"max_value=%.3f\"%np.max(nparray),\"max_position=%.0f\"%np.argmax(nparray))\n",
    "# done function\n",
    "\n",
    "def print_df(name,df,doForce=False):\n",
    "    if debug or doForce:\n",
    "        print(name,\"shape\",df.shape)\n",
    "        # print(df.head())\n",
    "        # print(df.tail())\n",
    "        print(df)\n",
    "# done function\n",
    "\n",
    "# df means panda data frame\n",
    "def get_df_from_file(name,inputFileName):\n",
    "    if debug:\n",
    "        print(\"name\",name,\"inputFileName\",inputFileName)\n",
    "    df=pd.read_csv(inputFileName)\n",
    "    print_df(name,df)\n",
    "    return df\n",
    "# done function\n",
    "\n",
    "def get_df_hits_for_one_event(eventNumber):\n",
    "    df_hits_recon=get_df_from_file(\"df_hits_recon\",inputFolderName+\"/event\"+eventNumber+\"-hits.csv\")\n",
    "    df_hits_truth=get_df_from_file(\"df_hits_truth\",inputFolderName+\"/event\"+eventNumber+\"-truth.csv\")\n",
    "    df_particles=get_df_from_file(\"df_particles\",inputFolderName+\"/event\"+eventNumber+\"-particles.csv\")\n",
    "    # combine df_hits_recon and df_hits_truth into a common df_hits\n",
    "    df_hits=pd.concat([df_hits_recon,df_hits_truth],axis=1,sort=False)    \n",
    "    print_df(\"df_hits\",df_hits)\n",
    "    return df_hits\n",
    "# done function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hit_id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>volume_id</th>\n",
       "      <th>layer_id</th>\n",
       "      <th>module_id</th>\n",
       "      <th>hit_id</th>\n",
       "      <th>particle_id</th>\n",
       "      <th>tx</th>\n",
       "      <th>ty</th>\n",
       "      <th>tz</th>\n",
       "      <th>tpx</th>\n",
       "      <th>tpy</th>\n",
       "      <th>tpz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>53.6895</td>\n",
       "      <td>8.814610</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18014467228958720</td>\n",
       "      <td>53.6668</td>\n",
       "      <td>8.821300</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>0.973584</td>\n",
       "      <td>0.159988</td>\n",
       "      <td>-28.120100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>70.7608</td>\n",
       "      <td>7.700570</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22528787094700032</td>\n",
       "      <td>70.7375</td>\n",
       "      <td>7.716360</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>0.213369</td>\n",
       "      <td>0.023315</td>\n",
       "      <td>-4.386220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>80.2306</td>\n",
       "      <td>11.405000</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>63052593806442496</td>\n",
       "      <td>80.2098</td>\n",
       "      <td>11.402000</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>0.050232</td>\n",
       "      <td>0.007147</td>\n",
       "      <td>-0.985516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>63.7141</td>\n",
       "      <td>4.036390</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>103588701304520704</td>\n",
       "      <td>63.7169</td>\n",
       "      <td>4.024370</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>0.196107</td>\n",
       "      <td>0.012337</td>\n",
       "      <td>-4.797500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>63.8302</td>\n",
       "      <td>3.995370</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>117101080734597120</td>\n",
       "      <td>63.8096</td>\n",
       "      <td>4.002310</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>0.049758</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>-1.159650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>36.3365</td>\n",
       "      <td>4.188840</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>144119998439227392</td>\n",
       "      <td>36.3572</td>\n",
       "      <td>4.189920</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>0.694746</td>\n",
       "      <td>0.080082</td>\n",
       "      <td>-29.166000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>96.2093</td>\n",
       "      <td>13.916400</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>171138366388043776</td>\n",
       "      <td>96.2000</td>\n",
       "      <td>13.922400</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>0.050748</td>\n",
       "      <td>0.007344</td>\n",
       "      <td>-0.724195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>64.9762</td>\n",
       "      <td>-0.528659</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>193658151231291392</td>\n",
       "      <td>64.9890</td>\n",
       "      <td>-0.507529</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>0.278147</td>\n",
       "      <td>-0.002304</td>\n",
       "      <td>-6.462090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>78.1766</td>\n",
       "      <td>10.842100</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>193663717508907008</td>\n",
       "      <td>78.1625</td>\n",
       "      <td>10.828700</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>0.616585</td>\n",
       "      <td>0.085178</td>\n",
       "      <td>-11.910600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>32.7480</td>\n",
       "      <td>1.749780</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>193666603726929920</td>\n",
       "      <td>32.7255</td>\n",
       "      <td>1.737070</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>0.140097</td>\n",
       "      <td>0.007304</td>\n",
       "      <td>-6.463650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>59.0844</td>\n",
       "      <td>4.073270</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>265720761791021056</td>\n",
       "      <td>59.0666</td>\n",
       "      <td>4.073540</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>0.524897</td>\n",
       "      <td>0.035988</td>\n",
       "      <td>-14.063500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>35.8941</td>\n",
       "      <td>5.508200</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>310756070869958656</td>\n",
       "      <td>35.9174</td>\n",
       "      <td>5.499020</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>0.191017</td>\n",
       "      <td>0.029297</td>\n",
       "      <td>-8.412450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>57.1875</td>\n",
       "      <td>7.384650</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>342277145092947968</td>\n",
       "      <td>57.2092</td>\n",
       "      <td>7.377480</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>0.358553</td>\n",
       "      <td>0.046191</td>\n",
       "      <td>-10.225900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>31.1857</td>\n",
       "      <td>1.526510</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>351285581298270208</td>\n",
       "      <td>31.1994</td>\n",
       "      <td>1.521440</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>0.242327</td>\n",
       "      <td>0.011882</td>\n",
       "      <td>-11.743600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>38.9310</td>\n",
       "      <td>1.333600</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>387315958865199104</td>\n",
       "      <td>38.9537</td>\n",
       "      <td>1.339340</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>0.123601</td>\n",
       "      <td>0.004212</td>\n",
       "      <td>-4.730160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>97.3358</td>\n",
       "      <td>4.124600</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>396326113057439744</td>\n",
       "      <td>97.3293</td>\n",
       "      <td>4.114020</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>0.420551</td>\n",
       "      <td>0.017871</td>\n",
       "      <td>-6.752580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>54.2201</td>\n",
       "      <td>9.959760</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>414331578034946048</td>\n",
       "      <td>54.2010</td>\n",
       "      <td>9.959970</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>0.684423</td>\n",
       "      <td>0.125937</td>\n",
       "      <td>-19.526400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>83.6008</td>\n",
       "      <td>10.165600</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>418836895649234944</td>\n",
       "      <td>83.6041</td>\n",
       "      <td>10.181600</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>0.231653</td>\n",
       "      <td>0.028237</td>\n",
       "      <td>-4.259260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>45.4299</td>\n",
       "      <td>5.506360</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>436852668548251648</td>\n",
       "      <td>45.4509</td>\n",
       "      <td>5.490020</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>0.250895</td>\n",
       "      <td>0.030284</td>\n",
       "      <td>-8.047670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>85.4042</td>\n",
       "      <td>2.082160</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>468376285391880192</td>\n",
       "      <td>85.3936</td>\n",
       "      <td>2.102120</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>0.166312</td>\n",
       "      <td>0.004124</td>\n",
       "      <td>-2.989810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>67.7352</td>\n",
       "      <td>1.694670</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>481885984762363904</td>\n",
       "      <td>67.7437</td>\n",
       "      <td>1.710910</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>0.077364</td>\n",
       "      <td>0.001945</td>\n",
       "      <td>-1.758210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>36.3859</td>\n",
       "      <td>4.995200</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>486388897195032576</td>\n",
       "      <td>36.3614</td>\n",
       "      <td>4.982970</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>0.162859</td>\n",
       "      <td>0.022371</td>\n",
       "      <td>-6.389960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>76.4289</td>\n",
       "      <td>5.939860</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>499900795588706304</td>\n",
       "      <td>76.4424</td>\n",
       "      <td>5.944070</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>0.671174</td>\n",
       "      <td>0.052267</td>\n",
       "      <td>-13.051500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>38.1360</td>\n",
       "      <td>4.982480</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>589973818928267264</td>\n",
       "      <td>38.1197</td>\n",
       "      <td>5.004950</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>0.573545</td>\n",
       "      <td>0.075351</td>\n",
       "      <td>-23.158800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>30.3794</td>\n",
       "      <td>3.168310</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>598983423364694016</td>\n",
       "      <td>30.3978</td>\n",
       "      <td>3.178410</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>0.656383</td>\n",
       "      <td>0.068597</td>\n",
       "      <td>-31.264000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>58.8525</td>\n",
       "      <td>9.170790</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>598992906652483584</td>\n",
       "      <td>58.8733</td>\n",
       "      <td>9.171700</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>0.528654</td>\n",
       "      <td>0.082341</td>\n",
       "      <td>-13.002100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>73.0069</td>\n",
       "      <td>12.140500</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>616995691570397184</td>\n",
       "      <td>73.0002</td>\n",
       "      <td>12.141300</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>0.494864</td>\n",
       "      <td>0.082335</td>\n",
       "      <td>-10.338000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>59.4029</td>\n",
       "      <td>2.894620</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>635023421658365952</td>\n",
       "      <td>59.3905</td>\n",
       "      <td>2.889930</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>0.322247</td>\n",
       "      <td>0.015661</td>\n",
       "      <td>-8.448120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>92.1941</td>\n",
       "      <td>14.252400</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>644017151895666688</td>\n",
       "      <td>92.1850</td>\n",
       "      <td>14.262900</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>0.238168</td>\n",
       "      <td>0.036928</td>\n",
       "      <td>-4.143290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>82.6161</td>\n",
       "      <td>10.489300</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>671036688075587584</td>\n",
       "      <td>82.6335</td>\n",
       "      <td>10.486000</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>0.920428</td>\n",
       "      <td>0.116946</td>\n",
       "      <td>-15.855100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116863</th>\n",
       "      <td>116863</td>\n",
       "      <td>-495.2280</td>\n",
       "      <td>790.844000</td>\n",
       "      <td>2952.5</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>90</td>\n",
       "      <td>116863</td>\n",
       "      <td>684547143360356352</td>\n",
       "      <td>-497.2240</td>\n",
       "      <td>794.499000</td>\n",
       "      <td>2952.5</td>\n",
       "      <td>-0.113421</td>\n",
       "      <td>0.178737</td>\n",
       "      <td>0.631667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116864</th>\n",
       "      <td>116864</td>\n",
       "      <td>-533.1700</td>\n",
       "      <td>738.440000</td>\n",
       "      <td>2955.5</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>91</td>\n",
       "      <td>116864</td>\n",
       "      <td>103586914598125568</td>\n",
       "      <td>-534.9170</td>\n",
       "      <td>740.784000</td>\n",
       "      <td>2955.5</td>\n",
       "      <td>-0.333723</td>\n",
       "      <td>0.462158</td>\n",
       "      <td>1.808680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116865</th>\n",
       "      <td>116865</td>\n",
       "      <td>-463.7700</td>\n",
       "      <td>737.442000</td>\n",
       "      <td>2955.5</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>91</td>\n",
       "      <td>116865</td>\n",
       "      <td>126111097487884288</td>\n",
       "      <td>-464.3240</td>\n",
       "      <td>738.235000</td>\n",
       "      <td>2955.5</td>\n",
       "      <td>-0.080143</td>\n",
       "      <td>0.127417</td>\n",
       "      <td>0.519451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116866</th>\n",
       "      <td>116866</td>\n",
       "      <td>-500.2560</td>\n",
       "      <td>775.208000</td>\n",
       "      <td>2955.5</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>91</td>\n",
       "      <td>116866</td>\n",
       "      <td>238695178297147392</td>\n",
       "      <td>-502.4220</td>\n",
       "      <td>778.133000</td>\n",
       "      <td>2955.5</td>\n",
       "      <td>-0.252536</td>\n",
       "      <td>0.391102</td>\n",
       "      <td>1.534320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116867</th>\n",
       "      <td>116867</td>\n",
       "      <td>-601.6000</td>\n",
       "      <td>740.143000</td>\n",
       "      <td>2955.5</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>91</td>\n",
       "      <td>116867</td>\n",
       "      <td>342273640399634432</td>\n",
       "      <td>-602.5100</td>\n",
       "      <td>741.334000</td>\n",
       "      <td>2955.5</td>\n",
       "      <td>-0.816029</td>\n",
       "      <td>1.004060</td>\n",
       "      <td>3.827700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116868</th>\n",
       "      <td>116868</td>\n",
       "      <td>-495.2050</td>\n",
       "      <td>791.733000</td>\n",
       "      <td>2955.5</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>91</td>\n",
       "      <td>116868</td>\n",
       "      <td>684547143360356352</td>\n",
       "      <td>-497.7630</td>\n",
       "      <td>795.347000</td>\n",
       "      <td>2955.5</td>\n",
       "      <td>-0.113421</td>\n",
       "      <td>0.178737</td>\n",
       "      <td>0.631667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116869</th>\n",
       "      <td>116869</td>\n",
       "      <td>-602.2320</td>\n",
       "      <td>740.970000</td>\n",
       "      <td>2952.5</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>92</td>\n",
       "      <td>116869</td>\n",
       "      <td>342273640399634432</td>\n",
       "      <td>-601.8700</td>\n",
       "      <td>740.547000</td>\n",
       "      <td>2952.5</td>\n",
       "      <td>-0.816029</td>\n",
       "      <td>1.004060</td>\n",
       "      <td>3.827700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116870</th>\n",
       "      <td>116870</td>\n",
       "      <td>-679.7840</td>\n",
       "      <td>725.211000</td>\n",
       "      <td>2952.5</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>92</td>\n",
       "      <td>116870</td>\n",
       "      <td>396324807387381760</td>\n",
       "      <td>-682.4850</td>\n",
       "      <td>728.047000</td>\n",
       "      <td>2952.5</td>\n",
       "      <td>-0.404073</td>\n",
       "      <td>0.431046</td>\n",
       "      <td>1.712540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116871</th>\n",
       "      <td>116871</td>\n",
       "      <td>-624.9430</td>\n",
       "      <td>705.377000</td>\n",
       "      <td>2952.5</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>92</td>\n",
       "      <td>116871</td>\n",
       "      <td>477382660012900352</td>\n",
       "      <td>-623.7570</td>\n",
       "      <td>704.162000</td>\n",
       "      <td>2952.5</td>\n",
       "      <td>-0.906054</td>\n",
       "      <td>1.022840</td>\n",
       "      <td>4.256190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116872</th>\n",
       "      <td>116872</td>\n",
       "      <td>-597.5890</td>\n",
       "      <td>631.196000</td>\n",
       "      <td>2952.5</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>92</td>\n",
       "      <td>116872</td>\n",
       "      <td>635008165934530560</td>\n",
       "      <td>-595.0730</td>\n",
       "      <td>628.472000</td>\n",
       "      <td>2952.5</td>\n",
       "      <td>-0.445387</td>\n",
       "      <td>0.470374</td>\n",
       "      <td>2.169180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116873</th>\n",
       "      <td>116873</td>\n",
       "      <td>-684.3530</td>\n",
       "      <td>692.387000</td>\n",
       "      <td>2952.5</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>92</td>\n",
       "      <td>116873</td>\n",
       "      <td>756605768190394368</td>\n",
       "      <td>-682.5250</td>\n",
       "      <td>690.460000</td>\n",
       "      <td>2952.5</td>\n",
       "      <td>-0.360021</td>\n",
       "      <td>0.364204</td>\n",
       "      <td>1.494150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116874</th>\n",
       "      <td>116874</td>\n",
       "      <td>-672.8280</td>\n",
       "      <td>550.304000</td>\n",
       "      <td>2955.5</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>93</td>\n",
       "      <td>116874</td>\n",
       "      <td>126110272854163456</td>\n",
       "      <td>-672.3590</td>\n",
       "      <td>549.908000</td>\n",
       "      <td>2955.5</td>\n",
       "      <td>-0.225097</td>\n",
       "      <td>0.184095</td>\n",
       "      <td>1.007550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116875</th>\n",
       "      <td>116875</td>\n",
       "      <td>-670.0960</td>\n",
       "      <td>602.553000</td>\n",
       "      <td>2955.5</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>93</td>\n",
       "      <td>116875</td>\n",
       "      <td>283726776524664832</td>\n",
       "      <td>-669.2300</td>\n",
       "      <td>601.878000</td>\n",
       "      <td>2955.5</td>\n",
       "      <td>-0.340975</td>\n",
       "      <td>0.327195</td>\n",
       "      <td>1.512290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116876</th>\n",
       "      <td>116876</td>\n",
       "      <td>-764.3220</td>\n",
       "      <td>635.495000</td>\n",
       "      <td>2955.5</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>93</td>\n",
       "      <td>116876</td>\n",
       "      <td>504408655823634432</td>\n",
       "      <td>-761.8160</td>\n",
       "      <td>633.463000</td>\n",
       "      <td>2955.5</td>\n",
       "      <td>-0.359581</td>\n",
       "      <td>0.298989</td>\n",
       "      <td>1.420410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116877</th>\n",
       "      <td>116877</td>\n",
       "      <td>-718.5950</td>\n",
       "      <td>609.191000</td>\n",
       "      <td>2955.5</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>93</td>\n",
       "      <td>116877</td>\n",
       "      <td>864698275280715776</td>\n",
       "      <td>-718.8140</td>\n",
       "      <td>609.424000</td>\n",
       "      <td>2955.5</td>\n",
       "      <td>-0.580648</td>\n",
       "      <td>0.492281</td>\n",
       "      <td>2.418610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116878</th>\n",
       "      <td>116878</td>\n",
       "      <td>-773.1530</td>\n",
       "      <td>442.691000</td>\n",
       "      <td>2952.5</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>94</td>\n",
       "      <td>116878</td>\n",
       "      <td>22520678196445184</td>\n",
       "      <td>-777.0720</td>\n",
       "      <td>445.110000</td>\n",
       "      <td>2952.5</td>\n",
       "      <td>-0.158381</td>\n",
       "      <td>0.090725</td>\n",
       "      <td>0.611602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116879</th>\n",
       "      <td>116879</td>\n",
       "      <td>-770.2960</td>\n",
       "      <td>466.602000</td>\n",
       "      <td>2952.5</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>94</td>\n",
       "      <td>116879</td>\n",
       "      <td>351286337212514304</td>\n",
       "      <td>-774.0460</td>\n",
       "      <td>468.955000</td>\n",
       "      <td>2952.5</td>\n",
       "      <td>-1.711050</td>\n",
       "      <td>1.036640</td>\n",
       "      <td>6.506950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116880</th>\n",
       "      <td>116880</td>\n",
       "      <td>-900.9470</td>\n",
       "      <td>395.506000</td>\n",
       "      <td>2955.5</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>95</td>\n",
       "      <td>116880</td>\n",
       "      <td>369308501022867456</td>\n",
       "      <td>-901.8180</td>\n",
       "      <td>395.980000</td>\n",
       "      <td>2955.5</td>\n",
       "      <td>-0.859767</td>\n",
       "      <td>0.377519</td>\n",
       "      <td>2.797540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116881</th>\n",
       "      <td>116881</td>\n",
       "      <td>-882.6800</td>\n",
       "      <td>361.049000</td>\n",
       "      <td>2955.5</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>95</td>\n",
       "      <td>116881</td>\n",
       "      <td>409827566091177984</td>\n",
       "      <td>-881.5690</td>\n",
       "      <td>360.583000</td>\n",
       "      <td>2955.5</td>\n",
       "      <td>-0.147796</td>\n",
       "      <td>0.060063</td>\n",
       "      <td>0.473960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116882</th>\n",
       "      <td>116882</td>\n",
       "      <td>-845.8240</td>\n",
       "      <td>390.521000</td>\n",
       "      <td>2955.5</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>95</td>\n",
       "      <td>116882</td>\n",
       "      <td>423343037897244672</td>\n",
       "      <td>-842.5380</td>\n",
       "      <td>388.911000</td>\n",
       "      <td>2955.5</td>\n",
       "      <td>-0.064783</td>\n",
       "      <td>0.029902</td>\n",
       "      <td>0.227256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116883</th>\n",
       "      <td>116883</td>\n",
       "      <td>-846.3020</td>\n",
       "      <td>438.357000</td>\n",
       "      <td>2955.5</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>95</td>\n",
       "      <td>116883</td>\n",
       "      <td>936752021027946496</td>\n",
       "      <td>-847.4740</td>\n",
       "      <td>438.902000</td>\n",
       "      <td>2955.5</td>\n",
       "      <td>-0.253955</td>\n",
       "      <td>0.131521</td>\n",
       "      <td>0.887955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116884</th>\n",
       "      <td>116884</td>\n",
       "      <td>-842.2040</td>\n",
       "      <td>254.407000</td>\n",
       "      <td>2952.5</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>96</td>\n",
       "      <td>116884</td>\n",
       "      <td>225180118807478272</td>\n",
       "      <td>-846.4130</td>\n",
       "      <td>255.795000</td>\n",
       "      <td>2952.5</td>\n",
       "      <td>-0.222301</td>\n",
       "      <td>0.067188</td>\n",
       "      <td>0.776603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116885</th>\n",
       "      <td>116885</td>\n",
       "      <td>-972.4400</td>\n",
       "      <td>151.480000</td>\n",
       "      <td>2955.5</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>97</td>\n",
       "      <td>116885</td>\n",
       "      <td>553943097763954688</td>\n",
       "      <td>-968.0480</td>\n",
       "      <td>150.636000</td>\n",
       "      <td>2955.5</td>\n",
       "      <td>-0.653522</td>\n",
       "      <td>0.101706</td>\n",
       "      <td>2.007340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116886</th>\n",
       "      <td>116886</td>\n",
       "      <td>-981.5590</td>\n",
       "      <td>214.683000</td>\n",
       "      <td>2955.5</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>97</td>\n",
       "      <td>116886</td>\n",
       "      <td>716081549161791488</td>\n",
       "      <td>-980.3100</td>\n",
       "      <td>214.490000</td>\n",
       "      <td>2955.5</td>\n",
       "      <td>-0.180671</td>\n",
       "      <td>0.039529</td>\n",
       "      <td>0.552578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116887</th>\n",
       "      <td>116887</td>\n",
       "      <td>-882.1970</td>\n",
       "      <td>148.314000</td>\n",
       "      <td>2955.5</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>97</td>\n",
       "      <td>116887</td>\n",
       "      <td>905227579550597120</td>\n",
       "      <td>-883.0130</td>\n",
       "      <td>148.465000</td>\n",
       "      <td>2955.5</td>\n",
       "      <td>-0.097570</td>\n",
       "      <td>0.016406</td>\n",
       "      <td>0.328549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116888</th>\n",
       "      <td>116888</td>\n",
       "      <td>-961.3640</td>\n",
       "      <td>53.089300</td>\n",
       "      <td>2952.5</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>98</td>\n",
       "      <td>116888</td>\n",
       "      <td>585472418324152320</td>\n",
       "      <td>-956.7110</td>\n",
       "      <td>52.813800</td>\n",
       "      <td>2952.5</td>\n",
       "      <td>-1.442520</td>\n",
       "      <td>0.079645</td>\n",
       "      <td>4.686170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116889</th>\n",
       "      <td>116889</td>\n",
       "      <td>-972.9560</td>\n",
       "      <td>34.460400</td>\n",
       "      <td>2952.5</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>98</td>\n",
       "      <td>116889</td>\n",
       "      <td>671040467646808064</td>\n",
       "      <td>-973.8240</td>\n",
       "      <td>34.573000</td>\n",
       "      <td>2952.5</td>\n",
       "      <td>-0.447856</td>\n",
       "      <td>0.015907</td>\n",
       "      <td>1.394060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116890</th>\n",
       "      <td>116890</td>\n",
       "      <td>-937.8320</td>\n",
       "      <td>95.856100</td>\n",
       "      <td>2952.5</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>98</td>\n",
       "      <td>116890</td>\n",
       "      <td>765613654639902720</td>\n",
       "      <td>-937.8470</td>\n",
       "      <td>95.889000</td>\n",
       "      <td>2952.5</td>\n",
       "      <td>-0.404170</td>\n",
       "      <td>0.041329</td>\n",
       "      <td>1.265240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116891</th>\n",
       "      <td>116891</td>\n",
       "      <td>-901.0230</td>\n",
       "      <td>18.392000</td>\n",
       "      <td>2952.5</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>98</td>\n",
       "      <td>116891</td>\n",
       "      <td>765620801465483264</td>\n",
       "      <td>-896.3470</td>\n",
       "      <td>18.075200</td>\n",
       "      <td>2952.5</td>\n",
       "      <td>-0.147255</td>\n",
       "      <td>0.002971</td>\n",
       "      <td>0.482319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116892</th>\n",
       "      <td>116892</td>\n",
       "      <td>-876.7830</td>\n",
       "      <td>72.416600</td>\n",
       "      <td>2952.5</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>98</td>\n",
       "      <td>116892</td>\n",
       "      <td>851182322437849088</td>\n",
       "      <td>-878.9670</td>\n",
       "      <td>72.611800</td>\n",
       "      <td>2952.5</td>\n",
       "      <td>-1.352290</td>\n",
       "      <td>0.111683</td>\n",
       "      <td>4.583150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116893 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        hit_id         x           y       z  volume_id  layer_id  module_id  \\\n",
       "0            0   53.6895    8.814610 -1502.5          7         2          1   \n",
       "1            1   70.7608    7.700570 -1502.5          7         2          1   \n",
       "2            2   80.2306   11.405000 -1502.5          7         2          1   \n",
       "3            3   63.7141    4.036390 -1502.5          7         2          1   \n",
       "4            4   63.8302    3.995370 -1502.5          7         2          1   \n",
       "5            5   36.3365    4.188840 -1502.5          7         2          1   \n",
       "6            6   96.2093   13.916400 -1502.5          7         2          1   \n",
       "7            7   64.9762   -0.528659 -1502.5          7         2          1   \n",
       "8            8   78.1766   10.842100 -1502.5          7         2          1   \n",
       "9            9   32.7480    1.749780 -1502.5          7         2          1   \n",
       "10          10   59.0844    4.073270 -1502.5          7         2          1   \n",
       "11          11   35.8941    5.508200 -1502.5          7         2          1   \n",
       "12          12   57.1875    7.384650 -1502.5          7         2          1   \n",
       "13          13   31.1857    1.526510 -1502.5          7         2          1   \n",
       "14          14   38.9310    1.333600 -1502.5          7         2          1   \n",
       "15          15   97.3358    4.124600 -1502.5          7         2          1   \n",
       "16          16   54.2201    9.959760 -1502.5          7         2          1   \n",
       "17          17   83.6008   10.165600 -1502.5          7         2          1   \n",
       "18          18   45.4299    5.506360 -1502.5          7         2          1   \n",
       "19          19   85.4042    2.082160 -1502.5          7         2          1   \n",
       "20          20   67.7352    1.694670 -1502.5          7         2          1   \n",
       "21          21   36.3859    4.995200 -1502.5          7         2          1   \n",
       "22          22   76.4289    5.939860 -1502.5          7         2          1   \n",
       "23          23   38.1360    4.982480 -1502.5          7         2          1   \n",
       "24          24   30.3794    3.168310 -1502.5          7         2          1   \n",
       "25          25   58.8525    9.170790 -1502.5          7         2          1   \n",
       "26          26   73.0069   12.140500 -1502.5          7         2          1   \n",
       "27          27   59.4029    2.894620 -1502.5          7         2          1   \n",
       "28          28   92.1941   14.252400 -1502.5          7         2          1   \n",
       "29          29   82.6161   10.489300 -1502.5          7         2          1   \n",
       "...        ...       ...         ...     ...        ...       ...        ...   \n",
       "116863  116863 -495.2280  790.844000  2952.5         18        12         90   \n",
       "116864  116864 -533.1700  738.440000  2955.5         18        12         91   \n",
       "116865  116865 -463.7700  737.442000  2955.5         18        12         91   \n",
       "116866  116866 -500.2560  775.208000  2955.5         18        12         91   \n",
       "116867  116867 -601.6000  740.143000  2955.5         18        12         91   \n",
       "116868  116868 -495.2050  791.733000  2955.5         18        12         91   \n",
       "116869  116869 -602.2320  740.970000  2952.5         18        12         92   \n",
       "116870  116870 -679.7840  725.211000  2952.5         18        12         92   \n",
       "116871  116871 -624.9430  705.377000  2952.5         18        12         92   \n",
       "116872  116872 -597.5890  631.196000  2952.5         18        12         92   \n",
       "116873  116873 -684.3530  692.387000  2952.5         18        12         92   \n",
       "116874  116874 -672.8280  550.304000  2955.5         18        12         93   \n",
       "116875  116875 -670.0960  602.553000  2955.5         18        12         93   \n",
       "116876  116876 -764.3220  635.495000  2955.5         18        12         93   \n",
       "116877  116877 -718.5950  609.191000  2955.5         18        12         93   \n",
       "116878  116878 -773.1530  442.691000  2952.5         18        12         94   \n",
       "116879  116879 -770.2960  466.602000  2952.5         18        12         94   \n",
       "116880  116880 -900.9470  395.506000  2955.5         18        12         95   \n",
       "116881  116881 -882.6800  361.049000  2955.5         18        12         95   \n",
       "116882  116882 -845.8240  390.521000  2955.5         18        12         95   \n",
       "116883  116883 -846.3020  438.357000  2955.5         18        12         95   \n",
       "116884  116884 -842.2040  254.407000  2952.5         18        12         96   \n",
       "116885  116885 -972.4400  151.480000  2955.5         18        12         97   \n",
       "116886  116886 -981.5590  214.683000  2955.5         18        12         97   \n",
       "116887  116887 -882.1970  148.314000  2955.5         18        12         97   \n",
       "116888  116888 -961.3640   53.089300  2952.5         18        12         98   \n",
       "116889  116889 -972.9560   34.460400  2952.5         18        12         98   \n",
       "116890  116890 -937.8320   95.856100  2952.5         18        12         98   \n",
       "116891  116891 -901.0230   18.392000  2952.5         18        12         98   \n",
       "116892  116892 -876.7830   72.416600  2952.5         18        12         98   \n",
       "\n",
       "        hit_id         particle_id        tx          ty      tz       tpx  \\\n",
       "0            0   18014467228958720   53.6668    8.821300 -1502.5  0.973584   \n",
       "1            1   22528787094700032   70.7375    7.716360 -1502.5  0.213369   \n",
       "2            2   63052593806442496   80.2098   11.402000 -1502.5  0.050232   \n",
       "3            3  103588701304520704   63.7169    4.024370 -1502.5  0.196107   \n",
       "4            4  117101080734597120   63.8096    4.002310 -1502.5  0.049758   \n",
       "5            5  144119998439227392   36.3572    4.189920 -1502.5  0.694746   \n",
       "6            6  171138366388043776   96.2000   13.922400 -1502.5  0.050748   \n",
       "7            7  193658151231291392   64.9890   -0.507529 -1502.5  0.278147   \n",
       "8            8  193663717508907008   78.1625   10.828700 -1502.5  0.616585   \n",
       "9            9  193666603726929920   32.7255    1.737070 -1502.5  0.140097   \n",
       "10          10  265720761791021056   59.0666    4.073540 -1502.5  0.524897   \n",
       "11          11  310756070869958656   35.9174    5.499020 -1502.5  0.191017   \n",
       "12          12  342277145092947968   57.2092    7.377480 -1502.5  0.358553   \n",
       "13          13  351285581298270208   31.1994    1.521440 -1502.5  0.242327   \n",
       "14          14  387315958865199104   38.9537    1.339340 -1502.5  0.123601   \n",
       "15          15  396326113057439744   97.3293    4.114020 -1502.5  0.420551   \n",
       "16          16  414331578034946048   54.2010    9.959970 -1502.5  0.684423   \n",
       "17          17  418836895649234944   83.6041   10.181600 -1502.5  0.231653   \n",
       "18          18  436852668548251648   45.4509    5.490020 -1502.5  0.250895   \n",
       "19          19  468376285391880192   85.3936    2.102120 -1502.5  0.166312   \n",
       "20          20  481885984762363904   67.7437    1.710910 -1502.5  0.077364   \n",
       "21          21  486388897195032576   36.3614    4.982970 -1502.5  0.162859   \n",
       "22          22  499900795588706304   76.4424    5.944070 -1502.5  0.671174   \n",
       "23          23  589973818928267264   38.1197    5.004950 -1502.5  0.573545   \n",
       "24          24  598983423364694016   30.3978    3.178410 -1502.5  0.656383   \n",
       "25          25  598992906652483584   58.8733    9.171700 -1502.5  0.528654   \n",
       "26          26  616995691570397184   73.0002   12.141300 -1502.5  0.494864   \n",
       "27          27  635023421658365952   59.3905    2.889930 -1502.5  0.322247   \n",
       "28          28  644017151895666688   92.1850   14.262900 -1502.5  0.238168   \n",
       "29          29  671036688075587584   82.6335   10.486000 -1502.5  0.920428   \n",
       "...        ...                 ...       ...         ...     ...       ...   \n",
       "116863  116863  684547143360356352 -497.2240  794.499000  2952.5 -0.113421   \n",
       "116864  116864  103586914598125568 -534.9170  740.784000  2955.5 -0.333723   \n",
       "116865  116865  126111097487884288 -464.3240  738.235000  2955.5 -0.080143   \n",
       "116866  116866  238695178297147392 -502.4220  778.133000  2955.5 -0.252536   \n",
       "116867  116867  342273640399634432 -602.5100  741.334000  2955.5 -0.816029   \n",
       "116868  116868  684547143360356352 -497.7630  795.347000  2955.5 -0.113421   \n",
       "116869  116869  342273640399634432 -601.8700  740.547000  2952.5 -0.816029   \n",
       "116870  116870  396324807387381760 -682.4850  728.047000  2952.5 -0.404073   \n",
       "116871  116871  477382660012900352 -623.7570  704.162000  2952.5 -0.906054   \n",
       "116872  116872  635008165934530560 -595.0730  628.472000  2952.5 -0.445387   \n",
       "116873  116873  756605768190394368 -682.5250  690.460000  2952.5 -0.360021   \n",
       "116874  116874  126110272854163456 -672.3590  549.908000  2955.5 -0.225097   \n",
       "116875  116875  283726776524664832 -669.2300  601.878000  2955.5 -0.340975   \n",
       "116876  116876  504408655823634432 -761.8160  633.463000  2955.5 -0.359581   \n",
       "116877  116877  864698275280715776 -718.8140  609.424000  2955.5 -0.580648   \n",
       "116878  116878   22520678196445184 -777.0720  445.110000  2952.5 -0.158381   \n",
       "116879  116879  351286337212514304 -774.0460  468.955000  2952.5 -1.711050   \n",
       "116880  116880  369308501022867456 -901.8180  395.980000  2955.5 -0.859767   \n",
       "116881  116881  409827566091177984 -881.5690  360.583000  2955.5 -0.147796   \n",
       "116882  116882  423343037897244672 -842.5380  388.911000  2955.5 -0.064783   \n",
       "116883  116883  936752021027946496 -847.4740  438.902000  2955.5 -0.253955   \n",
       "116884  116884  225180118807478272 -846.4130  255.795000  2952.5 -0.222301   \n",
       "116885  116885  553943097763954688 -968.0480  150.636000  2955.5 -0.653522   \n",
       "116886  116886  716081549161791488 -980.3100  214.490000  2955.5 -0.180671   \n",
       "116887  116887  905227579550597120 -883.0130  148.465000  2955.5 -0.097570   \n",
       "116888  116888  585472418324152320 -956.7110   52.813800  2952.5 -1.442520   \n",
       "116889  116889  671040467646808064 -973.8240   34.573000  2952.5 -0.447856   \n",
       "116890  116890  765613654639902720 -937.8470   95.889000  2952.5 -0.404170   \n",
       "116891  116891  765620801465483264 -896.3470   18.075200  2952.5 -0.147255   \n",
       "116892  116892  851182322437849088 -878.9670   72.611800  2952.5 -1.352290   \n",
       "\n",
       "             tpy        tpz  \n",
       "0       0.159988 -28.120100  \n",
       "1       0.023315  -4.386220  \n",
       "2       0.007147  -0.985516  \n",
       "3       0.012337  -4.797500  \n",
       "4       0.003124  -1.159650  \n",
       "5       0.080082 -29.166000  \n",
       "6       0.007344  -0.724195  \n",
       "7      -0.002304  -6.462090  \n",
       "8       0.085178 -11.910600  \n",
       "9       0.007304  -6.463650  \n",
       "10      0.035988 -14.063500  \n",
       "11      0.029297  -8.412450  \n",
       "12      0.046191 -10.225900  \n",
       "13      0.011882 -11.743600  \n",
       "14      0.004212  -4.730160  \n",
       "15      0.017871  -6.752580  \n",
       "16      0.125937 -19.526400  \n",
       "17      0.028237  -4.259260  \n",
       "18      0.030284  -8.047670  \n",
       "19      0.004124  -2.989810  \n",
       "20      0.001945  -1.758210  \n",
       "21      0.022371  -6.389960  \n",
       "22      0.052267 -13.051500  \n",
       "23      0.075351 -23.158800  \n",
       "24      0.068597 -31.264000  \n",
       "25      0.082341 -13.002100  \n",
       "26      0.082335 -10.338000  \n",
       "27      0.015661  -8.448120  \n",
       "28      0.036928  -4.143290  \n",
       "29      0.116946 -15.855100  \n",
       "...          ...        ...  \n",
       "116863  0.178737   0.631667  \n",
       "116864  0.462158   1.808680  \n",
       "116865  0.127417   0.519451  \n",
       "116866  0.391102   1.534320  \n",
       "116867  1.004060   3.827700  \n",
       "116868  0.178737   0.631667  \n",
       "116869  1.004060   3.827700  \n",
       "116870  0.431046   1.712540  \n",
       "116871  1.022840   4.256190  \n",
       "116872  0.470374   2.169180  \n",
       "116873  0.364204   1.494150  \n",
       "116874  0.184095   1.007550  \n",
       "116875  0.327195   1.512290  \n",
       "116876  0.298989   1.420410  \n",
       "116877  0.492281   2.418610  \n",
       "116878  0.090725   0.611602  \n",
       "116879  1.036640   6.506950  \n",
       "116880  0.377519   2.797540  \n",
       "116881  0.060063   0.473960  \n",
       "116882  0.029902   0.227256  \n",
       "116883  0.131521   0.887955  \n",
       "116884  0.067188   0.776603  \n",
       "116885  0.101706   2.007340  \n",
       "116886  0.039529   0.552578  \n",
       "116887  0.016406   0.328549  \n",
       "116888  0.079645   4.686170  \n",
       "116889  0.015907   1.394060  \n",
       "116890  0.041329   1.265240  \n",
       "116891  0.002971   0.482319  \n",
       "116892  0.111683   4.583150  \n",
       "\n",
       "[116893 rows x 15 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hits=get_df_hits_for_one_event(eventNumber)\n",
    "# print_df(\"df_hits\",df_hits,True)\n",
    "df_hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 29124\n",
      "4 24923\n",
      "6 20030\n",
      "8 18354\n",
      "10 9433\n",
      "12 9438\n",
      "14 5591\n"
     ]
    }
   ],
   "source": [
    "nparray_layer_id=df_hits[\"layer_id\"]\n",
    "# print(nparray_layer_id)\n",
    "dict_id_counter={}\n",
    "for e in nparray_layer_id:\n",
    "    if e in dict_id_counter:\n",
    "        dict_id_counter[e]+=1\n",
    "    else:\n",
    "        dict_id_counter[e]=1\n",
    "for e in sorted(dict_id_counter.keys()):\n",
    "    print(e,dict_id_counter[e]) \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from this we learned that the first layer has id 2 and there are around 29k hits and for each of these we will use annoy to find the 20 nearest neighbors in direction, which we will use to train an test the neural network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annoy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from annoy import AnnoyIndex\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildAnnoyIndex(data,metric=\"angular\",ntrees=10):\n",
    "    f=len(data[0])\n",
    "    print(\"f\",f)\n",
    "    t=AnnoyIndex(f,metric)\n",
    "    print(\"type(t)\",type(t))\n",
    "    print(\"enumerate data\")\n",
    "    for i,d in enumerate(data):\n",
    "        if debug:\n",
    "            print(\"i\",i,\"d\",d)\n",
    "        t.add_item(i,d)\n",
    "    # done for loop\n",
    "    t.build(ntrees) # 10 trees\n",
    "    return t\n",
    "# done function\n",
    "\n",
    "def study_annoy(df_hits,debug):\n",
    "    nparray_position=df_hits[[\"x\",\"y\",\"z\"]].values\n",
    "    #print_nparray(\"nparray_position\",nparray_position)\n",
    "    #return\n",
    "    index=buildAnnoyIndex(nparray_position,metric=\"angular\",ntrees=10)\n",
    "    if debug or verbose:\n",
    "        print(\"type(index)\",index)\n",
    "        print(\"len(df_hits)\",len(df_hits))\n",
    "    n=random.choice(range(len(df_hits)))\n",
    "    if debug or verbose:\n",
    "        print(\"n\",n)\n",
    "    list_index=index.get_nns_by_item(n,bucketSize)\n",
    "    if debug or verbose:\n",
    "        print(\"list_index\",list_index)\n",
    "    nparray_index=np.array(list_index)\n",
    "    df_bucket=df_hits.iloc[nparray_index]\n",
    "    plt.plot(df_bucket.x,df_bucket.y,\"o\")\n",
    "    plt.plot(0,0,\"r+\")\n",
    "    plt.show()\n",
    "    plt.savefig(outputFolderName+\"/test.pdf\")\n",
    "    return df_bucket\n",
    "# done function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f 3\n",
      "type(t) <class 'annoy.Annoy'>\n",
      "enumerate data\n",
      "type(index) <annoy.Annoy object at 0x7fbb15bb2f30>\n",
      "len(df_hits) 116893\n",
      "n 44938\n",
      "list_index [44938, 44933, 32389, 44936, 25284, 33286, 79292, 23377, 39202, 39198, 25344, 44934, 25345, 23456, 85175, 44937, 79286, 79650, 79646, 25315]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hit_id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>volume_id</th>\n",
       "      <th>layer_id</th>\n",
       "      <th>module_id</th>\n",
       "      <th>hit_id</th>\n",
       "      <th>particle_id</th>\n",
       "      <th>tx</th>\n",
       "      <th>ty</th>\n",
       "      <th>tz</th>\n",
       "      <th>tpx</th>\n",
       "      <th>tpy</th>\n",
       "      <th>tpz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44938</th>\n",
       "      <td>44938</td>\n",
       "      <td>-172.5080</td>\n",
       "      <td>-1.992290</td>\n",
       "      <td>-225.7490</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>235</td>\n",
       "      <td>44938</td>\n",
       "      <td>873699908257841152</td>\n",
       "      <td>-172.5090</td>\n",
       "      <td>-1.986220</td>\n",
       "      <td>-225.7480</td>\n",
       "      <td>-0.661996</td>\n",
       "      <td>-0.007576</td>\n",
       "      <td>-0.437701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44933</th>\n",
       "      <td>44933</td>\n",
       "      <td>-172.0990</td>\n",
       "      <td>-4.237210</td>\n",
       "      <td>-222.0100</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>235</td>\n",
       "      <td>44933</td>\n",
       "      <td>40533633596915712</td>\n",
       "      <td>-172.1010</td>\n",
       "      <td>-4.226780</td>\n",
       "      <td>-222.0100</td>\n",
       "      <td>-1.873490</td>\n",
       "      <td>-0.045941</td>\n",
       "      <td>-2.047530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32389</th>\n",
       "      <td>32389</td>\n",
       "      <td>-73.3085</td>\n",
       "      <td>0.809727</td>\n",
       "      <td>-95.6567</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>161</td>\n",
       "      <td>32389</td>\n",
       "      <td>909731247897444352</td>\n",
       "      <td>-73.3103</td>\n",
       "      <td>0.817098</td>\n",
       "      <td>-95.6561</td>\n",
       "      <td>-0.313392</td>\n",
       "      <td>0.003473</td>\n",
       "      <td>0.127014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44936</th>\n",
       "      <td>44936</td>\n",
       "      <td>-171.6200</td>\n",
       "      <td>-6.865320</td>\n",
       "      <td>-223.9390</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>235</td>\n",
       "      <td>44936</td>\n",
       "      <td>666532813570416640</td>\n",
       "      <td>-171.6210</td>\n",
       "      <td>-6.860490</td>\n",
       "      <td>-223.9380</td>\n",
       "      <td>-0.483363</td>\n",
       "      <td>-0.019271</td>\n",
       "      <td>-0.570252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25284</th>\n",
       "      <td>25284</td>\n",
       "      <td>-32.0551</td>\n",
       "      <td>-1.239450</td>\n",
       "      <td>-41.0837</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>112</td>\n",
       "      <td>25284</td>\n",
       "      <td>238698270673600512</td>\n",
       "      <td>-32.0541</td>\n",
       "      <td>-1.221700</td>\n",
       "      <td>-41.0832</td>\n",
       "      <td>-1.460110</td>\n",
       "      <td>-0.056313</td>\n",
       "      <td>2.550910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33286</th>\n",
       "      <td>33286</td>\n",
       "      <td>-71.1435</td>\n",
       "      <td>0.795103</td>\n",
       "      <td>-96.5342</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>192</td>\n",
       "      <td>33286</td>\n",
       "      <td>909731247897444352</td>\n",
       "      <td>-71.1434</td>\n",
       "      <td>0.793083</td>\n",
       "      <td>-96.5343</td>\n",
       "      <td>-0.313392</td>\n",
       "      <td>0.003473</td>\n",
       "      <td>0.127014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79292</th>\n",
       "      <td>79292</td>\n",
       "      <td>-256.9840</td>\n",
       "      <td>-10.237200</td>\n",
       "      <td>-324.7970</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>281</td>\n",
       "      <td>79292</td>\n",
       "      <td>666532813570416640</td>\n",
       "      <td>-256.9860</td>\n",
       "      <td>-10.263800</td>\n",
       "      <td>-324.6490</td>\n",
       "      <td>-0.483363</td>\n",
       "      <td>-0.019271</td>\n",
       "      <td>-0.570252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23377</th>\n",
       "      <td>23377</td>\n",
       "      <td>-34.1729</td>\n",
       "      <td>0.980364</td>\n",
       "      <td>-44.5691</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>97</td>\n",
       "      <td>23377</td>\n",
       "      <td>157626811591688192</td>\n",
       "      <td>-34.1761</td>\n",
       "      <td>0.989643</td>\n",
       "      <td>-44.5727</td>\n",
       "      <td>-1.013960</td>\n",
       "      <td>0.029958</td>\n",
       "      <td>0.550619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39202</th>\n",
       "      <td>39202</td>\n",
       "      <td>-116.5150</td>\n",
       "      <td>-4.670250</td>\n",
       "      <td>-158.9270</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>209</td>\n",
       "      <td>39202</td>\n",
       "      <td>666532813570416640</td>\n",
       "      <td>-116.5160</td>\n",
       "      <td>-4.663600</td>\n",
       "      <td>-158.9280</td>\n",
       "      <td>-0.483363</td>\n",
       "      <td>-0.019271</td>\n",
       "      <td>-0.570252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39198</th>\n",
       "      <td>39198</td>\n",
       "      <td>-116.8780</td>\n",
       "      <td>-2.882700</td>\n",
       "      <td>-161.6590</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>209</td>\n",
       "      <td>39198</td>\n",
       "      <td>40533633596915712</td>\n",
       "      <td>-116.8800</td>\n",
       "      <td>-2.872690</td>\n",
       "      <td>-161.6590</td>\n",
       "      <td>-1.873490</td>\n",
       "      <td>-0.045941</td>\n",
       "      <td>-2.047530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25344</th>\n",
       "      <td>25344</td>\n",
       "      <td>-32.0889</td>\n",
       "      <td>-1.838500</td>\n",
       "      <td>-42.1194</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>112</td>\n",
       "      <td>25344</td>\n",
       "      <td>671042185633726464</td>\n",
       "      <td>-32.0880</td>\n",
       "      <td>-1.821380</td>\n",
       "      <td>-42.1190</td>\n",
       "      <td>-0.127586</td>\n",
       "      <td>-0.007184</td>\n",
       "      <td>0.145540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44934</th>\n",
       "      <td>44934</td>\n",
       "      <td>-171.0330</td>\n",
       "      <td>-10.085000</td>\n",
       "      <td>-225.0360</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>235</td>\n",
       "      <td>44934</td>\n",
       "      <td>103583478624288768</td>\n",
       "      <td>-171.0350</td>\n",
       "      <td>-10.075200</td>\n",
       "      <td>-225.0360</td>\n",
       "      <td>-0.355931</td>\n",
       "      <td>-0.021000</td>\n",
       "      <td>-0.585825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25345</th>\n",
       "      <td>25345</td>\n",
       "      <td>-32.0946</td>\n",
       "      <td>-1.938340</td>\n",
       "      <td>-42.5094</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>112</td>\n",
       "      <td>25345</td>\n",
       "      <td>716077907029524480</td>\n",
       "      <td>-32.0931</td>\n",
       "      <td>-1.911390</td>\n",
       "      <td>-42.5217</td>\n",
       "      <td>-0.262554</td>\n",
       "      <td>-0.015673</td>\n",
       "      <td>0.002289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23456</th>\n",
       "      <td>23456</td>\n",
       "      <td>-33.1380</td>\n",
       "      <td>-1.979620</td>\n",
       "      <td>-42.5094</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>97</td>\n",
       "      <td>23456</td>\n",
       "      <td>716077907029524480</td>\n",
       "      <td>-33.1400</td>\n",
       "      <td>-1.973880</td>\n",
       "      <td>-42.5126</td>\n",
       "      <td>-0.262554</td>\n",
       "      <td>-0.015673</td>\n",
       "      <td>0.002289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85175</th>\n",
       "      <td>85175</td>\n",
       "      <td>-360.3770</td>\n",
       "      <td>-14.385400</td>\n",
       "      <td>-446.2000</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>337</td>\n",
       "      <td>85175</td>\n",
       "      <td>666532813570416640</td>\n",
       "      <td>-360.3770</td>\n",
       "      <td>-14.385800</td>\n",
       "      <td>-446.6260</td>\n",
       "      <td>-0.483363</td>\n",
       "      <td>-0.019271</td>\n",
       "      <td>-0.570252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44937</th>\n",
       "      <td>44937</td>\n",
       "      <td>-170.8040</td>\n",
       "      <td>-11.342000</td>\n",
       "      <td>-224.2260</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>235</td>\n",
       "      <td>44937</td>\n",
       "      <td>851181703962558464</td>\n",
       "      <td>-170.8050</td>\n",
       "      <td>-11.338600</td>\n",
       "      <td>-224.2250</td>\n",
       "      <td>-0.822923</td>\n",
       "      <td>-0.054720</td>\n",
       "      <td>-0.952636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79286</th>\n",
       "      <td>79286</td>\n",
       "      <td>-256.7000</td>\n",
       "      <td>-6.273790</td>\n",
       "      <td>-314.4000</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>281</td>\n",
       "      <td>79286</td>\n",
       "      <td>40533633596915712</td>\n",
       "      <td>-256.7020</td>\n",
       "      <td>-6.301340</td>\n",
       "      <td>-314.4710</td>\n",
       "      <td>-1.873490</td>\n",
       "      <td>-0.045941</td>\n",
       "      <td>-2.047530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79650</th>\n",
       "      <td>79650</td>\n",
       "      <td>-260.2070</td>\n",
       "      <td>9.519140</td>\n",
       "      <td>-330.0000</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>320</td>\n",
       "      <td>79650</td>\n",
       "      <td>238692154640171008</td>\n",
       "      <td>-260.2110</td>\n",
       "      <td>9.499470</td>\n",
       "      <td>-330.0750</td>\n",
       "      <td>-0.470302</td>\n",
       "      <td>0.017141</td>\n",
       "      <td>-0.421051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79646</th>\n",
       "      <td>79646</td>\n",
       "      <td>-260.1660</td>\n",
       "      <td>9.694490</td>\n",
       "      <td>-328.8000</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>320</td>\n",
       "      <td>79646</td>\n",
       "      <td>126104844015501312</td>\n",
       "      <td>-260.1660</td>\n",
       "      <td>9.694810</td>\n",
       "      <td>-328.9740</td>\n",
       "      <td>-1.299030</td>\n",
       "      <td>0.048290</td>\n",
       "      <td>-1.372820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25315</th>\n",
       "      <td>25315</td>\n",
       "      <td>-31.9284</td>\n",
       "      <td>1.006980</td>\n",
       "      <td>-44.0834</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>112</td>\n",
       "      <td>25315</td>\n",
       "      <td>486393570119385088</td>\n",
       "      <td>-31.9287</td>\n",
       "      <td>1.001550</td>\n",
       "      <td>-44.0831</td>\n",
       "      <td>-0.561420</td>\n",
       "      <td>0.017859</td>\n",
       "      <td>0.555375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       hit_id         x          y         z  volume_id  layer_id  module_id  \\\n",
       "44938   44938 -172.5080  -1.992290 -225.7490          8         8        235   \n",
       "44933   44933 -172.0990  -4.237210 -222.0100          8         8        235   \n",
       "32389   32389  -73.3085   0.809727  -95.6567          8         4        161   \n",
       "44936   44936 -171.6200  -6.865320 -223.9390          8         8        235   \n",
       "25284   25284  -32.0551  -1.239450  -41.0837          8         2        112   \n",
       "33286   33286  -71.1435   0.795103  -96.5342          8         4        192   \n",
       "79292   79292 -256.9840 -10.237200 -324.7970         13         2        281   \n",
       "23377   23377  -34.1729   0.980364  -44.5691          8         2         97   \n",
       "39202   39202 -116.5150  -4.670250 -158.9270          8         6        209   \n",
       "39198   39198 -116.8780  -2.882700 -161.6590          8         6        209   \n",
       "25344   25344  -32.0889  -1.838500  -42.1194          8         2        112   \n",
       "44934   44934 -171.0330 -10.085000 -225.0360          8         8        235   \n",
       "25345   25345  -32.0946  -1.938340  -42.5094          8         2        112   \n",
       "23456   23456  -33.1380  -1.979620  -42.5094          8         2         97   \n",
       "85175   85175 -360.3770 -14.385400 -446.2000         13         4        337   \n",
       "44937   44937 -170.8040 -11.342000 -224.2260          8         8        235   \n",
       "79286   79286 -256.7000  -6.273790 -314.4000         13         2        281   \n",
       "79650   79650 -260.2070   9.519140 -330.0000         13         2        320   \n",
       "79646   79646 -260.1660   9.694490 -328.8000         13         2        320   \n",
       "25315   25315  -31.9284   1.006980  -44.0834          8         2        112   \n",
       "\n",
       "       hit_id         particle_id        tx         ty        tz       tpx  \\\n",
       "44938   44938  873699908257841152 -172.5090  -1.986220 -225.7480 -0.661996   \n",
       "44933   44933   40533633596915712 -172.1010  -4.226780 -222.0100 -1.873490   \n",
       "32389   32389  909731247897444352  -73.3103   0.817098  -95.6561 -0.313392   \n",
       "44936   44936  666532813570416640 -171.6210  -6.860490 -223.9380 -0.483363   \n",
       "25284   25284  238698270673600512  -32.0541  -1.221700  -41.0832 -1.460110   \n",
       "33286   33286  909731247897444352  -71.1434   0.793083  -96.5343 -0.313392   \n",
       "79292   79292  666532813570416640 -256.9860 -10.263800 -324.6490 -0.483363   \n",
       "23377   23377  157626811591688192  -34.1761   0.989643  -44.5727 -1.013960   \n",
       "39202   39202  666532813570416640 -116.5160  -4.663600 -158.9280 -0.483363   \n",
       "39198   39198   40533633596915712 -116.8800  -2.872690 -161.6590 -1.873490   \n",
       "25344   25344  671042185633726464  -32.0880  -1.821380  -42.1190 -0.127586   \n",
       "44934   44934  103583478624288768 -171.0350 -10.075200 -225.0360 -0.355931   \n",
       "25345   25345  716077907029524480  -32.0931  -1.911390  -42.5217 -0.262554   \n",
       "23456   23456  716077907029524480  -33.1400  -1.973880  -42.5126 -0.262554   \n",
       "85175   85175  666532813570416640 -360.3770 -14.385800 -446.6260 -0.483363   \n",
       "44937   44937  851181703962558464 -170.8050 -11.338600 -224.2250 -0.822923   \n",
       "79286   79286   40533633596915712 -256.7020  -6.301340 -314.4710 -1.873490   \n",
       "79650   79650  238692154640171008 -260.2110   9.499470 -330.0750 -0.470302   \n",
       "79646   79646  126104844015501312 -260.1660   9.694810 -328.9740 -1.299030   \n",
       "25315   25315  486393570119385088  -31.9287   1.001550  -44.0831 -0.561420   \n",
       "\n",
       "            tpy       tpz  \n",
       "44938 -0.007576 -0.437701  \n",
       "44933 -0.045941 -2.047530  \n",
       "32389  0.003473  0.127014  \n",
       "44936 -0.019271 -0.570252  \n",
       "25284 -0.056313  2.550910  \n",
       "33286  0.003473  0.127014  \n",
       "79292 -0.019271 -0.570252  \n",
       "23377  0.029958  0.550619  \n",
       "39202 -0.019271 -0.570252  \n",
       "39198 -0.045941 -2.047530  \n",
       "25344 -0.007184  0.145540  \n",
       "44934 -0.021000 -0.585825  \n",
       "25345 -0.015673  0.002289  \n",
       "23456 -0.015673  0.002289  \n",
       "85175 -0.019271 -0.570252  \n",
       "44937 -0.054720 -0.952636  \n",
       "79286 -0.045941 -2.047530  \n",
       "79650  0.017141 -0.421051  \n",
       "79646  0.048290 -1.372820  \n",
       "25315  0.017859  0.555375  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_bucket=study_annoy(df_hits,debug)\n",
    "df_bucket\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nparray_inputValue(df_bucket,debug):\n",
    "    nparray_position=df_bucket[[\"x\",\"y\",\"z\"]].values\n",
    "    print_nparray(\"nparray_position\",nparray_position)\n",
    "    nparray_value=nparray_position.flatten()\n",
    "    return nparray_value\n",
    "# done function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "nparray nparray_inputValue\n",
      "[-172.508      -1.99229  -225.749    -172.099      -4.23721  -222.01\n",
      "  -73.3085      0.809727  -95.6567   -171.62       -6.86532  -223.939\n",
      "  -32.0551     -1.23945   -41.0837    -71.1435      0.795103  -96.5342\n",
      " -256.984     -10.2372   -324.797     -34.1729      0.980364  -44.5691\n",
      " -116.515      -4.67025  -158.927    -116.878      -2.8827   -161.659\n",
      "  -32.0889     -1.8385    -42.1194   -171.033     -10.085    -225.036\n",
      "  -32.0946     -1.93834   -42.5094    -33.138      -1.97962   -42.5094\n",
      " -360.377     -14.3854   -446.2      -170.804     -11.342    -224.226\n",
      " -256.7        -6.27379  -314.4      -260.207       9.51914  -330.\n",
      " -260.166       9.69449  -328.8       -31.9284      1.00698   -44.0834  ]\n",
      "type <class 'numpy.ndarray'> shape (60,) min_value=-446.200 min_position=44 max_value=9.694 max_position=55\n"
     ]
    }
   ],
   "source": [
    "nparray_inputValue=get_nparray_inputValue(df_bucket,debug)\n",
    "print_nparray(\"nparray_inputValue\",nparray_inputValue,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_particle_id_most_common(df_bucket,debug):\n",
    "    counter=Counter(df_bucket.particle_id.values)\n",
    "    list_tuple_most_common=counter.most_common()\n",
    "    tuple_most_common=list_tuple_most_common[0]\n",
    "    particle_id_most_common=tuple_most_common[0]\n",
    "    if debug:\n",
    "        print(\"particle_id_most_common\",particle_id_most_common)\n",
    "    return particle_id_most_common\n",
    "# done function\n",
    "\n",
    "def get_nparray_outputValue(df_bucket,debug):\n",
    "    list_outputValue=[]\n",
    "    particle_id_most_common=get_particle_id_most_common(df_bucket,debug)\n",
    "    for i in range (df_bucket.shape[0]):\n",
    "        hit=df_bucket.iloc[i]\n",
    "        particle_id=hit[\"particle_id\"]\n",
    "        if particle_id==particle_id_most_common:\n",
    "            output=1.0\n",
    "        else:\n",
    "            output=-1.0\n",
    "        if debug and False:\n",
    "            print(\"i\", i,\"particle_id\",particle_id,\"particle_id_most_common\",particle_id_most_common,\"output\",output)\n",
    "        list_outputValue.append(output)\n",
    "    # done for loop\n",
    "    nparray_outputValue=np.array(list_outputValue)\n",
    "    print_nparray(\"nparray_outputValue\",nparray_outputValue)\n",
    "    return nparray_outputValue\n",
    "# done function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write input and output to NN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "nparray nparray_outputValue\n",
      "[-1. -1. -1.  1. -1. -1.  1. -1.  1. -1. -1. -1. -1. -1.  1. -1. -1. -1.\n",
      " -1. -1.]\n",
      "type <class 'numpy.ndarray'> shape (20,) min_value=-1.000 min_position=0 max_value=1.000 max_position=3\n"
     ]
    }
   ],
   "source": [
    "nparray_outputValue=get_nparray_outputValue(df_bucket,debug)\n",
    "print_nparray(\"nparray_outputValue\",nparray_outputValue,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start doing input output for this event\n"
     ]
    }
   ],
   "source": [
    "print(\"Start doing input output for this event\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valueInputOutput=io\n",
    "list_io=\"Input,Output\".split(\",\")\n",
    "dict_io_fileName={}\n",
    "for io in list_io:\n",
    "    dict_io_fileName[io]=outputFolderName+\"/NN_1_data_\"+io+\"_\"+eventNumber+\".npy\"\n",
    "\n",
    "def write_to_file_NN_data_dict_io_nparray(df_hits):\n",
    "    nrHits=df_hits.shape[0]\n",
    "    if debug:\n",
    "        print(\"nrHits\",nrHits)\n",
    "    nparray_position=df_hits[[\"x\",\"y\",\"z\"]].values\n",
    "    print_nparray(\"nparray_position\",nparray_position)\n",
    "    index=buildAnnoyIndex(nparray_position,metric=\"angular\",ntrees=10)\n",
    "    if True:\n",
    "        print(\"annoy index built\")\n",
    "    if debug or verbose:\n",
    "        print(\"type(index)\",index)\n",
    "        print(\"len(df_hits)\",len(df_hits))\n",
    "    #    \n",
    "    dict_io_list_nparray_value={}\n",
    "    counterBucket=0\n",
    "    nparray_layer_id=df_hits[\"layer_id\"]\n",
    "    for i in range(nrHits):\n",
    "        if doTest==True:\n",
    "            if counterBucket>40:\n",
    "                continue\n",
    "        if debug:\n",
    "            print(\"i\",i,\"layer_id\",nparray_layer_id[i])\n",
    "        isFirstLayer=nparray_layer_id[i]==2\n",
    "        if isFirstLayer==False:\n",
    "            continue\n",
    "        counterBucket+=1\n",
    "        if debug or (verbose and counterBucket%100==0):\n",
    "            print(i,counterBucket)\n",
    "        # remaining i our hits from first layer\n",
    "        if debug:\n",
    "            print(\"print list_index for hit\",i)\n",
    "        list_index=index.get_nns_by_item(i,bucketSize)\n",
    "        if debug:\n",
    "            print(\"list_index\",list_index)\n",
    "        nparray_index=np.array(list_index)\n",
    "        if debug:\n",
    "            print(\"create df_bucket for\",i)\n",
    "        df_bucket=df_hits.iloc[nparray_index]\n",
    "        if debug:\n",
    "            print(\"end create df_bucket for\",i)\n",
    "        #\n",
    "        dict_io_nparray_value={}\n",
    "        dict_io_nparray_value[\"Input\"]=get_nparray_inputValue(df_bucket,debug)\n",
    "        dict_io_nparray_value[\"Output\"]=get_nparray_outputValue(df_bucket,debug)\n",
    "        for io in list_io:\n",
    "            if debug:\n",
    "                print_nparray(\"nparray_value \"+io,dict_io_nparray_value[io]) \n",
    "            if io not in dict_io_list_nparray_value:\n",
    "                dict_io_list_nparray_value[io]=[]\n",
    "            else:\n",
    "                dict_io_list_nparray_value[io].append(dict_io_nparray_value[io])\n",
    "            # done if\n",
    "        # done for loop over io\n",
    "    # done for loop over hits\n",
    "    if debug or verbose:\n",
    "        print(\"counterBucket\",counterBucket)\n",
    "    # done if\n",
    "    dict_io_nparray={}\n",
    "    for io in list_io:\n",
    "        print(\"length_\"+io,len(dict_io_list_nparray_value[io]))\n",
    "        # convert list_value to nparray\n",
    "        dict_io_nparray[io]=np.array(dict_io_list_nparray_value[io])\n",
    "        # print \n",
    "        print_nparray(io,dict_io_nparray[io])\n",
    "        # write nparray to file\n",
    "        np.save(dict_io_fileName[io],dict_io_nparray[io])\n",
    "    # done for loop over io\n",
    "# done function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "if doPrepareDataInputOutput:\n",
    "    write_to_file_NN_data_dict_io_nparray(df_hits)\n",
    "    print(\">>>> all done writing input and output in nparray for this event\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split input and output in train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valueTrainTest=tt\n",
    "list_tt=\"Train,Test\".split(\",\")\n",
    "\n",
    "dict_io_tt_fileName={}\n",
    "for io in list_io:\n",
    "    for tt in list_tt:\n",
    "        dict_io_tt_fileName[io+tt]=outputFolderName+\"/NN_2_data_\"+io+tt+\"_\"+eventNumber+\".npy\"\n",
    "        \n",
    "def write_to_file_NN_data_dict_io_tt_nparray():\n",
    "    dict_io_tt_nparray={}\n",
    "    for io in list_io:\n",
    "        nparray=np.load(dict_io_fileName[io])\n",
    "        print_nparray(io,nparray)\n",
    "        nrRow=nparray.shape[0]\n",
    "        # keep only an even number, to split train and test in equal number\n",
    "        if nrRow%2==1:\n",
    "            nrRow-=1\n",
    "        dict_tt_list_index={}\n",
    "        dict_tt_list_index[\"Train\"]=[i for i in range(nrRow) if i%2==0] # even indices\n",
    "        dict_tt_list_index[\"Test\"] =[i for i in range(nrRow) if i%2==1] # odd  indices\n",
    "        for tt in list_tt:\n",
    "            dict_io_tt_nparray[io+tt]=nparray[dict_tt_list_index[tt],:]\n",
    "            if io==\"Input\":\n",
    "                # reshape to have an extra dimension of size one, needed by Keras\n",
    "                dict_io_tt_nparray[io+tt]=dict_io_tt_nparray[io+tt].reshape(dict_io_tt_nparray[io+tt].shape[0],dict_io_tt_nparray[io+tt].shape[1],1)\n",
    "            # print\n",
    "            print_nparray(io+tt,dict_io_tt_nparray[io+tt])\n",
    "            # write nparray to file\n",
    "            np.save(dict_io_tt_fileName[io+tt],dict_io_tt_nparray[io+tt])\n",
    "        # done for loop over tt\n",
    "    # done for loop over io\n",
    "# done function\n",
    "\n",
    "def read_from_file_NN_data_dict_io_tt_nparray():\n",
    "    dict_io_tt_nparray={}\n",
    "    for io in list_io:\n",
    "        for tt in list_tt:\n",
    "            dict_io_tt_nparray[io+tt]=np.load(dict_io_tt_fileName[io+tt])\n",
    "            print_nparray(io+tt,dict_io_tt_nparray[io+tt])\n",
    "        # done for loop over tt\n",
    "    # done for loop over io\n",
    "    return dict_io_tt_nparray\n",
    "# done function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "if doPrepareDataInputOutput:\n",
    "    write_to_file_NN_data_dict_io_tt_nparray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create NN empty model, train, test, accuracy, loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to obtain reproducible results, meaning each new NN training to obtain the same result, set the seed of the random number now\n",
    "# np.random.seed(2019)\n",
    "# np.random.seed(20190825)\n",
    "np.random.seed(98383822)\n",
    "\n",
    "nrNodesInputLayer=bucketSize*3 # three inputs (x, y, z) for each hit in the batch\n",
    "nrNodesOutputLayer=bucketSize*1 # one output for each hit in the batch\n",
    "\n",
    "import keras\n",
    "# for DNN training with Keras\n",
    "# the order is layer and k (from architecture), nrEpoch, batchSize (from learning steps)\n",
    "\n",
    "numberOfEpochs=300\n",
    "\n",
    "if True:\n",
    "    list_infoNN=[\n",
    "        [\"A1\",1,numberOfEpochs,1000],\n",
    "        [\"B1\",1,numberOfEpochs,1000],\n",
    "        [\"C1\",1,numberOfEpochs,1000],\n",
    "        [\"D1\",1,numberOfEpochs,1000],\n",
    "        [\"E1\",1,numberOfEpochs,1000],\n",
    "        [\"F1\",1,numberOfEpochs,1000],\n",
    "        [\"G1\",1,numberOfEpochs,1000],\n",
    "        #\n",
    "        [\"A1\",2,numberOfEpochs,1000],\n",
    "        [\"B1\",2,numberOfEpochs,1000],\n",
    "        [\"C1\",2,numberOfEpochs,1000],\n",
    "        [\"D1\",2,numberOfEpochs,1000],\n",
    "        [\"E1\",2,numberOfEpochs,1000],\n",
    "        [\"F1\",2,numberOfEpochs,1000],\n",
    "        [\"G1\",2,numberOfEpochs,1000],\n",
    "        #\n",
    "        [\"A1\",3,numberOfEpochs,1000],\n",
    "        [\"B1\",3,numberOfEpochs,1000],\n",
    "        [\"C1\",3,numberOfEpochs,1000],\n",
    "        [\"D1\",3,numberOfEpochs,1000],\n",
    "        [\"E1\",3,numberOfEpochs,1000],\n",
    "        [\"F1\",3,numberOfEpochs,1000],\n",
    "        [\"G1\",3,numberOfEpochs,1000],      \n",
    "        # \n",
    "        [\"A1\",4,numberOfEpochs,1000],\n",
    "        [\"B1\",4,numberOfEpochs,1000],\n",
    "        [\"C1\",4,numberOfEpochs,1000],\n",
    "        [\"D1\",4,numberOfEpochs,1000],\n",
    "        [\"E1\",4,numberOfEpochs,1000],\n",
    "        [\"F1\",4,numberOfEpochs,1000],\n",
    "        [\"G1\",4,numberOfEpochs,1000],\n",
    "        #\n",
    "        [\"A2\",1,numberOfEpochs,1000],\n",
    "        [\"B2\",1,numberOfEpochs,1000],\n",
    "        [\"C2\",1,numberOfEpochs,1000],\n",
    "        [\"D2\",1,numberOfEpochs,1000],\n",
    "        [\"E2\",1,numberOfEpochs,1000],\n",
    "        [\"F2\",1,numberOfEpochs,1000],\n",
    "        [\"G2\",1,numberOfEpochs,1000],\n",
    "        #\n",
    "        [\"A2\",2,numberOfEpochs,1000],\n",
    "        [\"B2\",2,numberOfEpochs,1000],\n",
    "        [\"C2\",2,numberOfEpochs,1000],\n",
    "        [\"D2\",2,numberOfEpochs,1000],\n",
    "        [\"E2\",2,numberOfEpochs,1000],\n",
    "        [\"F2\",2,numberOfEpochs,1000],\n",
    "        [\"G2\",2,numberOfEpochs,1000],\n",
    "        #\n",
    "        [\"A2\",3,numberOfEpochs,1000],\n",
    "        [\"B2\",3,numberOfEpochs,1000],\n",
    "        [\"C2\",3,numberOfEpochs,1000],\n",
    "        [\"D2\",3,numberOfEpochs,1000],\n",
    "        [\"E2\",3,numberOfEpochs,1000],\n",
    "        [\"F2\",3,numberOfEpochs,1000],\n",
    "        [\"G2\",3,numberOfEpochs,1000],      \n",
    "        # \n",
    "        [\"A2\",4,numberOfEpochs,1000],\n",
    "        [\"B2\",4,numberOfEpochs,1000],\n",
    "        [\"C2\",4,numberOfEpochs,1000],\n",
    "        [\"D2\",4,numberOfEpochs,1000],\n",
    "        [\"E2\",4,numberOfEpochs,1000],\n",
    "        [\"F2\",4,numberOfEpochs,1000],\n",
    "        [\"G2\",4,numberOfEpochs,1000],\n",
    "        #\n",
    "        [\"A4\",1,numberOfEpochs,1000],\n",
    "        [\"B4\",1,numberOfEpochs,1000],\n",
    "        [\"C4\",1,numberOfEpochs,1000],\n",
    "        [\"D4\",1,numberOfEpochs,1000],\n",
    "        [\"E4\",1,numberOfEpochs,1000],\n",
    "        [\"F4\",1,numberOfEpochs,1000],\n",
    "        [\"G4\",1,numberOfEpochs,1000],\n",
    "        #\n",
    "        [\"A4\",2,numberOfEpochs,1000],\n",
    "        [\"B4\",2,numberOfEpochs,1000],\n",
    "        [\"C4\",2,numberOfEpochs,1000],\n",
    "        [\"D4\",2,numberOfEpochs,1000],\n",
    "        [\"E4\",2,numberOfEpochs,1000],\n",
    "        [\"F4\",2,numberOfEpochs,1000],\n",
    "        [\"G4\",2,numberOfEpochs,1000],\n",
    "        #\n",
    "        [\"A4\",3,numberOfEpochs,1000],\n",
    "        [\"B4\",3,numberOfEpochs,1000],\n",
    "        [\"C4\",3,numberOfEpochs,1000],\n",
    "        [\"D4\",3,numberOfEpochs,1000],\n",
    "        [\"E4\",3,numberOfEpochs,1000],\n",
    "        [\"F4\",3,numberOfEpochs,1000],\n",
    "        [\"G4\",3,numberOfEpochs,1000],      \n",
    "        # \n",
    "        [\"A4\",4,numberOfEpochs,1000],\n",
    "        [\"B4\",4,numberOfEpochs,1000],\n",
    "        [\"C4\",4,numberOfEpochs,1000],\n",
    "        [\"D4\",4,numberOfEpochs,1000],\n",
    "        [\"E4\",4,numberOfEpochs,1000],\n",
    "        [\"F4\",4,numberOfEpochs,1000],\n",
    "        [\"G4\",4,numberOfEpochs,1000],\n",
    "    ]\n",
    "\n",
    "\n",
    "if False:\n",
    "    list_infoNN=[\n",
    "        [\"A2\",4,30,1000],\n",
    "        [\"B2\",4,30,1000],\n",
    "     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_from_infoNN(infoNN):\n",
    "    layer=infoNN[0]\n",
    "    k=infoNN[1]\n",
    "    nrEpoch=infoNN[2]\n",
    "    batchSize=infoNN[3]\n",
    "    if debug:\n",
    "        print(\"get infoNN for\",\"layer\",layer,\"k\",str(k),\"nrEpoch\",str(nrEpoch),\"batchSize\",str(batchSize))\n",
    "    nameNN=\"l_\"+layer+\"_k_\"+str(k)+\"_e_\"+str(nrEpoch)+\"_b_\"+str(batchSize)\n",
    "    if debug:\n",
    "        print(\"nameNN\",nameNN)\n",
    "    # done if\n",
    "    return nameNN,layer,k,nrEpoch,batchSize\n",
    "# done function\n",
    "\n",
    "# create an empty NN model, and documentation related to it\n",
    "# https://keras.io/getting-started/sequential-model-guide/\n",
    "# https://keras.io/layers/core/\n",
    "# https://keras.io/activations/\n",
    "# https://keras.io/losses/\n",
    "def prepare_NN_model(layer=\"A3\",k=4):\n",
    "    if debug:\n",
    "        print(\"\")\n",
    "        print(\"Prepare empty NN model (fixed geometry and weights filled with random numbers).\")\n",
    "    if debug:\n",
    "        print(\"Start prepare model for layer\",layer,\"k\",k)\n",
    "    nrNodesHiddenLayer=bucketSize*k # let the user change this k as hyper-parameter\n",
    "    # create empty model\n",
    "    model=keras.models.Sequential()\n",
    "    # define the geometry by defining how many layers and how many nodes per layer\n",
    "    # add input layer\n",
    "    # Flatten(): https://stackoverflow.com/questions/44176982/how-flatten-layer-works-in-keras?rq=1\n",
    "    model.add(keras.layers.Dense(nrNodesInputLayer,activation='linear',input_shape=(nrNodesInputLayer,1)))\n",
    "    # flatten input layer\n",
    "    model.add(keras.layers.Flatten())\n",
    "    # split layer in letter and digit\n",
    "    layer_letter=layer[0] # letter means compilation option\n",
    "    layer_digit=layer[1] # digit means number of hidden layers\n",
    "    # add hidden layers\n",
    "    if layer_digit==\"1\":\n",
    "        model.add(keras.layers.Dense(nrNodesHiddenLayer,activation='relu'))\n",
    "    elif layer_digit==\"2\":\n",
    "        model.add(keras.layers.Dense(nrNodesHiddenLayer,activation='relu'))\n",
    "        model.add(keras.layers.Dense(nrNodesHiddenLayer,activation='relu'))\n",
    "    elif layer_digit==\"3\":\n",
    "        model.add(keras.layers.Dense(nrNodesHiddenLayer,activation='relu'))\n",
    "        model.add(keras.layers.Dense(nrNodesHiddenLayer,activation='relu'))\n",
    "        model.add(keras.layers.Dense(nrNodesOutputLayer,activation='relu'))\n",
    "    elif layer_digit==\"4\":\n",
    "        model.add(keras.layers.Dense(nrNodesHiddenLayer,activation='relu'))\n",
    "        model.add(keras.layers.Dense(nrNodesHiddenLayer,activation='relu'))\n",
    "        model.add(keras.layers.Dense(nrNodesOutputLayer,activation='relu'))\n",
    "        model.add(keras.layers.Dense(nrNodesOutputLayer,activation='relu'))\n",
    "    elif layer_digit==\"5\":\n",
    "        model.add(keras.layers.Dense(nrNodesHiddenLayer,activation='relu'))\n",
    "        model.add(keras.layers.Dense(nrNodesHiddenLayer,activation='relu'))\n",
    "        model.add(keras.layers.Dense(nrNodesOutputLayer,activation='relu'))\n",
    "        model.add(keras.layers.Dense(nrNodesOutputLayer,activation='relu'))\n",
    "        model.add(keras.layers.Dense(nrNodesOutputLayer,activation='relu'))\n",
    "    else:\n",
    "        print(\"layer_digit\",layer_digit,\"not known. Choose 1,2,3,4,5. WILL ABORT!!!\")\n",
    "        assert(False)\n",
    "    # done if\n",
    "    # finished defining the geometry, and now define how the NN learns (is trained)\n",
    "    if layer_letter==\"A\":\n",
    "        # add output layer\n",
    "        model.add(keras.layers.Dense(nrNodesOutputLayer,activation='tanh'))\n",
    "        model.compile(loss=keras.losses.hinge,\n",
    "                      optimizer=keras.optimizers.Adadelta(),\n",
    "                      metrics=['accuracy'])\n",
    "    elif layer_letter==\"B\":\n",
    "        # add output layer\n",
    "        model.add(keras.layers.Dense(nrNodesOutputLayer,activation='tanh'))\n",
    "        model.compile(loss=keras.losses.squared_hinge,\n",
    "                      optimizer=keras.optimizers.Adadelta(),\n",
    "                      metrics=['accuracy'])\n",
    "    elif layer_letter==\"C\":\n",
    "        # add output layer\n",
    "        model.add(keras.layers.Dense(nrNodesOutputLayer,activation='tanh'))\n",
    "        model.compile(loss=keras.losses.mean_squared_error,\n",
    "                      optimizer=keras.optimizers.Adadelta(),\n",
    "                      metrics=['accuracy'])\n",
    "    elif layer_letter==\"D\":\n",
    "        # add output layer\n",
    "        model.add(keras.layers.Dense(nrNodesOutputLayer,activation='tanh'))\n",
    "        model.compile(loss=keras.losses.mean_absolute_error,\n",
    "                      optimizer=keras.optimizers.Adadelta(),\n",
    "                      metrics=['accuracy'])\n",
    "    elif layer_letter==\"E\":\n",
    "        # add output layer\n",
    "        model.add(keras.layers.Dense(nrNodesOutputLayer,activation='tanh'))\n",
    "        model.compile(loss=keras.losses.mean_absolute_percentage_error,\n",
    "                      optimizer=keras.optimizers.Adadelta(),\n",
    "                      metrics=['accuracy'])\n",
    "    elif layer_letter==\"F\":\n",
    "        # add output layer\n",
    "        model.add(keras.layers.Dense(nrNodesOutputLayer,activation='tanh'))\n",
    "        model.compile(loss=keras.losses.mean_squared_logarithmic_error,\n",
    "                      optimizer=keras.optimizers.Adadelta(),\n",
    "                      metrics=['accuracy'])\n",
    "    elif layer_letter==\"G\":\n",
    "        # add output layer\n",
    "        model.add(keras.layers.Dense(nrNodesOutputLayer,activation='tanh'))\n",
    "        model.compile(loss=keras.losses.poisson,\n",
    "                      optimizer=keras.optimizers.Adadelta(),\n",
    "                      metrics=['accuracy'])\n",
    "    elif layer_letter==\"H\":\n",
    "        # add output layer\n",
    "        model.add(keras.layers.Dense(nrNodesOutputLayer,activation='softmax'))\n",
    "        model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                      optimizer=keras.optimizers.Adadelta(),\n",
    "                      metrics=['accuracy'])\n",
    "    elif layer_letter==\"I\":\n",
    "        # add output layer\n",
    "        model.add(keras.layers.Dense(nrNodesOutputLayer,activation='sigmoid'))\n",
    "        model.compile(loss=keras.losses.binary_crossentropy,\n",
    "                      optimizer=keras.optimizers.Adadelta(),\n",
    "                      metrics=['accuracy'])\n",
    "    else:\n",
    "        print(\"layer_letter\",layer_letter,\"not known. Choose A, B, ..., G, H,I. WILL ABORT!!!\")\n",
    "        assert(False)\n",
    "    # done if\n",
    "    if debug:\n",
    "        print(\"End   prepare model for layer\",layer,\"k\",k)\n",
    "    # done all, ready to return\n",
    "    return model\n",
    "# done function\n",
    "\n",
    "# valueLossAccuracy=la\n",
    "list_la=\"Loss,Accuracy\".split(\",\")\n",
    "\n",
    "dict_io_tt_fileName={}\n",
    "for io in list_io:\n",
    "    for tt in list_tt:\n",
    "        dict_io_tt_fileName[io+tt]=outputFolderName+\"/NN_2_data_\"+io+tt+\"_\"+eventNumber+\".npy\"\n",
    "        \n",
    "def get_dict_la_tt_fileName(nameNN):\n",
    "    dict_la_tt_fileName={}\n",
    "    for la in list_la:\n",
    "        for tt in list_tt:\n",
    "            dict_la_tt_fileName[la+tt]=outputFolderName+\"/NN_3_learn_\"+la+tt+\"_\"+nameNN+\".npy\"\n",
    "    dict_la_tt_fileName[\"nrEpoch\"]=outputFolderName+\"/NN_3_learn_\"+\"nrEpoch\"+\"_\"+nameNN+\".npy\"\n",
    "    # ready to return\n",
    "    return dict_la_tt_fileName\n",
    "# done function\n",
    "\n",
    "def get_fileNameWeights(nameNN):\n",
    "    fileNameWeights=outputFolderName+\"/NN_3_learn_model_weights_\"+nameNN+\".hdf5\"\n",
    "    if debug:\n",
    "        print(\"fileNameWeights\",fileNameWeights)\n",
    "    # done if\n",
    "    return fileNameWeights\n",
    "# done function\n",
    "        \n",
    "def train_NN_model(dict_io_tt_nparray,model,nameNN,nrEpoch,batchSize):\n",
    "    if debug or verbose:\n",
    "        print(\"Start train NN for\",nameNN)\n",
    "    # fit the model\n",
    "    for io in list_io:\n",
    "        for tt in list_tt:\n",
    "            print_nparray(io+\" \"+tt,dict_io_tt_nparray[io+tt])\n",
    "    # done forloop\n",
    "    h=model.fit(\n",
    "        dict_io_tt_nparray[\"Input\"+\"Train\"],dict_io_tt_nparray[\"Output\"+\"Train\"],\n",
    "        batch_size=batchSize,epochs=nrEpoch,verbose=verbose,\n",
    "        validation_data=(dict_io_tt_nparray[\"Input\"+\"Test\"],dict_io_tt_nparray[\"Output\"+\"Test\"]),\n",
    "        shuffle=False\n",
    "    )\n",
    "    if debug:\n",
    "        print(\"h.history\")\n",
    "        print(h.history)\n",
    "        print(\"h.history.keys()\")\n",
    "        print(h.history.keys())\n",
    "        print(\"print(h.history['val_loss'])\")\n",
    "        print(h.history['val_loss'],type(h.history['val_loss']))\n",
    "    # losses and accuracy\n",
    "    dict_la_tt_nparray={\n",
    "         \"Loss\"+\"Train\":np.array(h.history['loss']),\n",
    "         \"Loss\"+\"Test\":np.array(h.history['val_loss']),\n",
    "         \"Accuracy\"+\"Train\":np.array(h.history['acc']),\n",
    "         \"Accuracy\"+\"Test\":np.array(h.history['val_acc']),\n",
    "         \"nrEpoch\":np.array(range(nrEpoch)),\n",
    "     }\n",
    "    #\n",
    "    dict_la_tt_fileName=get_dict_la_tt_fileName(nameNN)\n",
    "    # write to .npy files\n",
    "    for key in dict_la_tt_nparray.keys():\n",
    "        np.save(dict_la_tt_fileName[key],dict_la_tt_nparray[key])\n",
    "    # done for loop\n",
    "    # write learned weights of the model to .hdf5\n",
    "    fileNameWeights=get_fileNameWeights(nameNN)\n",
    "    model.save_weights(fileNameWeights)\n",
    "    # finished all tasks, nothing to return\n",
    "    if debug or verbose:\n",
    "        print(\"End   train NN for\",nameNN)\n",
    "# done function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "if doTrainNN:\n",
    "    dict_io_tt_nparray=read_from_file_NN_data_dict_io_tt_nparray()\n",
    "    # loop over different NN that we compare (arhitecture and learning)\n",
    "    for infoNN in list_infoNN:\n",
    "        nameNN,layer,k,nrEpoch,batchSize=get_from_infoNN(infoNN)\n",
    "        # create empty train model architecture (layer and k), with bad initial random weights\n",
    "        model=prepare_NN_model(layer,k)\n",
    "        train_NN_model(dict_io_tt_nparray,model,nameNN=nameNN,nrEpoch=nrEpoch,batchSize=batchSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot overlay train and test for each NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_color=[\"r\",\"b\",\"m\",\"k\",\"g\",\"o\"]\n",
    "\n",
    "def overlayGraphsValues(list_tupleArray,outputFileName=\"overlay\",extensions=\"pdf,png\",info_x=[\"Procent of data reduced\",[0.0,1.0],\"linear\"],info_y=[\"Figure of merit of performance\",[0.0,100000.0],\"log\"],info_legend=[\"best\"],title=\"Loss and Accuracy\",debug=False):\n",
    "    if debug:\n",
    "        print(\"Start overlayGraphsValues\")\n",
    "        print(\"outputFileName\",outputFileName)\n",
    "        print(\"extensions\",extensions)\n",
    "        print(\"info_x\",info_x)\n",
    "        print(\"info_y\",info_y)\n",
    "        print(\"info_legend\",info_legend)\n",
    "        print(\"title\",title)\n",
    "    # x axis\n",
    "    x_label=info_x[0]\n",
    "    x_lim=info_x[1]\n",
    "    x_lim_min=x_lim[0]\n",
    "    x_lim_max=x_lim[1]\n",
    "    if x_lim_min==-1 and x_lim_max==-1:\n",
    "        x_set_lim=False\n",
    "    else:\n",
    "        x_set_lim=True\n",
    "    x_scale=info_x[2]\n",
    "    if debug:\n",
    "        print(\"x_label\",x_label,type(x_label))\n",
    "        print(\"x_lim_min\",x_lim_min,type(x_lim_min))\n",
    "        print(\"x_lim_max\",x_lim_max,type(x_lim_max))\n",
    "        print(\"x_set_lim\",x_set_lim,type(x_set_lim))\n",
    "        print(\"x_scale\",x_scale,type(x_scale))\n",
    "    # y axis\n",
    "    y_label=info_y[0]\n",
    "    y_lim=info_y[1]\n",
    "    y_lim_min=y_lim[0]\n",
    "    y_lim_max=y_lim[1]\n",
    "    if y_lim_min==-1 and y_lim_max==-1:\n",
    "        y_set_lim=False\n",
    "    else:\n",
    "        y_set_lim=True\n",
    "    y_scale=info_y[2]\n",
    "    if debug:\n",
    "        print(\"y_label\",y_label,type(y_label))\n",
    "        print(\"y_lim_min\",y_lim_min,type(y_lim_min))\n",
    "        print(\"y_lim_max\",y_lim_max,type(y_lim_max))\n",
    "        print(\"y_set_lim\",y_set_lim,type(y_set_lim))\n",
    "        print (\"y_scale\",y_scale,type(y_scale))\n",
    "    # create empty figure\n",
    "    plt.figure(1)\n",
    "    # set x-axis\n",
    "    plt.xlabel(x_label)\n",
    "    if x_set_lim==True:\n",
    "        plt.xlim(x_lim_min,x_lim_max)\n",
    "    plt.xscale(x_scale)\n",
    "    # set y-axis\n",
    "    plt.ylabel(y_label)\n",
    "    if y_set_lim==True:\n",
    "        plt.ylim(y_lim_min,y_lim_max)\n",
    "    plt.yscale(y_scale)\n",
    "    # set title\n",
    "    plt.title(title)\n",
    "    # fill content of plot\n",
    "    for i,tupleArray in enumerate(list_tupleArray):\n",
    "        if debug:\n",
    "            print(\"i\",i,\"len\",len(tupleArray))\n",
    "        x=tupleArray[0]\n",
    "        y=tupleArray[1]\n",
    "        c=tupleArray[2]\n",
    "        l=tupleArray[3]\n",
    "        plt.plot(x,y,c,label=l)\n",
    "    # done loop over each element to plot\n",
    "    # set legend\n",
    "    plt.legend(loc=info_legend[0])\n",
    "    # for each extension create a plot\n",
    "    for extension in extensions.split(\",\"):\n",
    "        fileNameFull=outputFileName+\".\"+extension\n",
    "        print(\"Saving plot at\",fileNameFull)\n",
    "        plt.savefig(fileNameFull)\n",
    "    # close the figure\n",
    "    plt.close()  \n",
    "# done function\n",
    "\n",
    "def plot_Loss_Accuracy(nameNN):\n",
    "    dict_la_tt_fileName=get_dict_la_tt_fileName(nameNN)\n",
    "    for la in list_la:\n",
    "        list_tupleArray=[]\n",
    "        nparray_x=np.load(dict_la_tt_fileName[\"nrEpoch\"])\n",
    "        print_nparray(\"x-nrEpoch\",nparray_x)\n",
    "        for i,tt in enumerate(list_tt):\n",
    "            nparray_y=np.load(dict_la_tt_fileName[la+tt])\n",
    "            print_nparray(\"y-\"+la+tt,nparray_y)\n",
    "            color=list_color[i]\n",
    "            legendName=la+\" \"+tt\n",
    "            list_tupleArray.append((nparray_x,nparray_y,color,legendName))\n",
    "        # done for loop\n",
    "        outputFileName=outputFolderName+\"/NN_plot1D_optionTrainTest_\"+la+\"_\"+nameNN\n",
    "        extensions=\"pdf\" # \"png,pdf\"\n",
    "        plotRange=[-1,-1]\n",
    "        overlayGraphsValues(list_tupleArray,outputFileName=outputFileName,extensions=extensions,\n",
    "                            info_x=[\"Number of epochs\",[-1,-1],\"linear\"],\n",
    "                            info_y=[\"Value of the \"+la+\" function\",plotRange,\"linear\"],\n",
    "                            info_legend=[\"best\"],title=\"NN_\"+la,debug=False) \n",
    "        # done for loop    \n",
    "# done function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_A1_k_1_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_A1_k_1_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_B1_k_1_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_B1_k_1_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_C1_k_1_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_C1_k_1_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_D1_k_1_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_D1_k_1_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_E1_k_1_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_E1_k_1_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_F1_k_1_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_F1_k_1_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_G1_k_1_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_G1_k_1_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_A1_k_2_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_A1_k_2_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_B1_k_2_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_B1_k_2_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_C1_k_2_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_C1_k_2_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_D1_k_2_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_D1_k_2_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_E1_k_2_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_E1_k_2_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_F1_k_2_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_F1_k_2_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_G1_k_2_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_G1_k_2_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_A1_k_3_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_A1_k_3_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_B1_k_3_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_B1_k_3_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_C1_k_3_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_C1_k_3_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_D1_k_3_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_D1_k_3_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_E1_k_3_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_E1_k_3_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_F1_k_3_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_F1_k_3_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_G1_k_3_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_G1_k_3_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_A1_k_4_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_A1_k_4_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_B1_k_4_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_B1_k_4_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_C1_k_4_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_C1_k_4_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_D1_k_4_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_D1_k_4_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_E1_k_4_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_E1_k_4_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_F1_k_4_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_F1_k_4_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_G1_k_4_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_G1_k_4_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_A2_k_1_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_A2_k_1_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_B2_k_1_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_B2_k_1_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_C2_k_1_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_C2_k_1_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_D2_k_1_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_D2_k_1_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_E2_k_1_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_E2_k_1_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_F2_k_1_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_F2_k_1_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_G2_k_1_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_G2_k_1_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_A2_k_2_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_A2_k_2_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_B2_k_2_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_B2_k_2_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_C2_k_2_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_C2_k_2_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_D2_k_2_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_D2_k_2_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_E2_k_2_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_E2_k_2_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_F2_k_2_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_F2_k_2_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_G2_k_2_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_G2_k_2_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_A2_k_3_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_A2_k_3_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_B2_k_3_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_B2_k_3_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_C2_k_3_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_C2_k_3_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_D2_k_3_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_D2_k_3_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_E2_k_3_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_E2_k_3_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_F2_k_3_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_F2_k_3_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_G2_k_3_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_G2_k_3_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_A2_k_4_e_300_b_1000.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_A2_k_4_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_B2_k_4_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_B2_k_4_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_C2_k_4_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_C2_k_4_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_D2_k_4_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_D2_k_4_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_E2_k_4_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_E2_k_4_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_F2_k_4_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_F2_k_4_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_G2_k_4_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_G2_k_4_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_A4_k_1_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_A4_k_1_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_B4_k_1_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_B4_k_1_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_C4_k_1_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_C4_k_1_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_D4_k_1_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_D4_k_1_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_E4_k_1_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_E4_k_1_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_F4_k_1_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_F4_k_1_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_G4_k_1_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_G4_k_1_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_A4_k_2_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_A4_k_2_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_B4_k_2_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_B4_k_2_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_C4_k_2_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_C4_k_2_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_D4_k_2_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_D4_k_2_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_E4_k_2_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_E4_k_2_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_F4_k_2_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_F4_k_2_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_G4_k_2_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_G4_k_2_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_A4_k_3_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_A4_k_3_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_B4_k_3_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_B4_k_3_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_C4_k_3_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_C4_k_3_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_D4_k_3_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_D4_k_3_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_E4_k_3_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_E4_k_3_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_F4_k_3_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_F4_k_3_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_G4_k_3_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_G4_k_3_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_A4_k_4_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_A4_k_4_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_B4_k_4_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_B4_k_4_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_C4_k_4_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_C4_k_4_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_D4_k_4_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_D4_k_4_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_E4_k_4_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_E4_k_4_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_F4_k_4_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_F4_k_4_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Loss_l_G4_k_4_e_300_b_1000.pdf\n",
      "Saving plot at ./output/NN_plot1D_optionTrainTest_Accuracy_l_G4_k_4_e_300_b_1000.pdf\n"
     ]
    }
   ],
   "source": [
    "if doPlot:\n",
    "    # loop over different NN that we compare (arhitecture and learning)\n",
    "    for infoNN in list_infoNN:\n",
    "        nameNN,layer,k,nrEpoch,batchSize=get_from_infoNN(infoNN)\n",
    "        plot_Loss_Accuracy(nameNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing NN prediction relative to output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pylab\n",
    "\n",
    "# histtype: bar, barstacked, step, stepfilled\n",
    "# nrBins: 100 or list of bins edges\n",
    "# option A: https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.axes.Axes.hist.html\n",
    "# only option A works if we want to add a text in the plot whose size is relative to the plot and not to the values plotted\n",
    "# option B: https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.hist.html\n",
    "# to color different bins in different colors, like a rainbow gradient https://stackoverflow.com/questions/23061657/plot-histogram-with-colors-taken-from-colormap\n",
    "# obtain the max value: # https://stackoverflow.com/questions/15558136/obtain-the-max-y-value-of-a-histogram\n",
    "# plotting two histograms in one plt.hist did not work for me easily, but I loop over list of arrays anyway, as I need to give them different labels and colors etc\n",
    "def overlay_histogram_from_nparray_with_ratio(list_tupleArray,outputFileName=\"./output_histo_from_nparray\",extensions=\"png,pdf\",nrBins=100,histtype=\"step\",info_x=[\"x-axis\"],info_y=[\"Number of points\"],title=\"Title\",text=None,info_legend=[\"best\"],list_color=\"r,g,b,k,y\".split(\",\"),doAddRatioPad=False,debug=False,verbose=False):\n",
    "    if debug:\n",
    "        print(\"Start draw_histogram_from_nparray()\")\n",
    "        print(\"outputFileName\",outputFileName)\n",
    "        print(\"extensions\",extensions)\n",
    "        print(\"info_x\",info_x)\n",
    "        print(\"info_y\",info_y)\n",
    "        print(\"title\",title)\n",
    "    # \n",
    "    max_y=np.NINF # negative infinity\n",
    "    fig=pylab.figure()\n",
    "    n_reference=0\n",
    "    for i,(nparray,legendText) in enumerate(list_tupleArray):\n",
    "        if debug:\n",
    "            print(\"i\",i,legendText,nparray)\n",
    "        if doAddRatioPad:\n",
    "            ax=fig.add_subplot(211)\n",
    "        else:\n",
    "            ax=fig.add_subplot(111)\n",
    "        n,b,patches=ax.hist(nparray,bins=nrBins,alpha=1.0,color=list_color[i],histtype=histtype,label=legendText)\n",
    "        if n.max()>max_y:\n",
    "            max_y=n.max()\n",
    "        if debug:\n",
    "            print_nparray(\"n\",n)\n",
    "            print_nparray(\"b\",b)\n",
    "            print(\"patches\",patches)\n",
    "            print(\"max_y\",max_y)\n",
    "        if doAddRatioPad:\n",
    "            if i==0:\n",
    "                n_reference=copy.deepcopy(n)\n",
    "            # calculate ratio of number of bins\n",
    "            n_ratio=n/n_reference\n",
    "            if debug:\n",
    "                print_nparray(\"n_reference\",n_reference)\n",
    "                print_nparray(\"n_ratio\",n_ratio)\n",
    "            # add the ratio as numpy arrays\n",
    "            ax2=fig.add_subplot(212)\n",
    "            ax2.plot(b[1:],n_ratio,c=list_color[i],label=legendText)\n",
    "        # done if doAddRatioPad\n",
    "    # done loop over histograms\n",
    "    # axes\n",
    "    x_label=info_x[0]\n",
    "    y_label=info_y[0]\n",
    "    # ax.set_xlabel(x_label)\n",
    "    ax.set_ylabel(y_label)\n",
    "    ax.set_ylim(0,max_y*1.2)\n",
    "    # title\n",
    "    ax.set_title(title)\n",
    "    # text\n",
    "    if text is not None:\n",
    "        ax.text(0.2,0.9,text,bbox=dict(facecolor='red', alpha=0.5),horizontalalignment=\"left\",fontstyle=\"oblique\",transform=ax.transAxes)\n",
    "    # legend\n",
    "    # set legend\n",
    "    ax.legend(loc=info_legend[0])\n",
    "    if doAddRatioPad:\n",
    "        ax2.legend(loc=info_legend[0])\n",
    "        ax2.set_ylabel(\"Ratio to \"+list_tupleArray[0][1])\n",
    "        ax2.set_xlabel(x_label)\n",
    "    else:\n",
    "        ax.set_xlabel(x_label)\n",
    "    # for each extension create a plot\n",
    "    for extension in extensions.split(\",\"):\n",
    "        fileNameFull=outputFileName+\".\"+extension\n",
    "        print(\"Saving plot at\",fileNameFull)\n",
    "        plt.savefig(fileNameFull)\n",
    "        # close the figure\n",
    "    plt.close()\n",
    "# done function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    list_infoNN=[\n",
    "        [\"A1\",1,numberOfEpochs,1000],\n",
    "        [\"B1\",1,numberOfEpochs,1000],\n",
    "        [\"C1\",1,numberOfEpochs,1000],\n",
    "        [\"D1\",1,numberOfEpochs,1000],\n",
    "        [\"E1\",1,numberOfEpochs,1000],\n",
    "        [\"F1\",1,numberOfEpochs,1000],\n",
    "        [\"G1\",1,numberOfEpochs,1000],\n",
    "        #\n",
    "        [\"A1\",2,numberOfEpochs,1000],\n",
    "        [\"B1\",2,numberOfEpochs,1000],\n",
    "        [\"C1\",2,numberOfEpochs,1000],\n",
    "        [\"D1\",2,numberOfEpochs,1000],\n",
    "        [\"E1\",2,numberOfEpochs,1000],\n",
    "        [\"F1\",2,numberOfEpochs,1000],\n",
    "        [\"G1\",2,numberOfEpochs,1000],\n",
    "        #\n",
    "        [\"A1\",3,numberOfEpochs,1000],\n",
    "        [\"B1\",3,numberOfEpochs,1000],\n",
    "        [\"C1\",3,numberOfEpochs,1000],\n",
    "        [\"D1\",3,numberOfEpochs,1000],\n",
    "        [\"E1\",3,numberOfEpochs,1000],\n",
    "        [\"F1\",3,numberOfEpochs,1000],\n",
    "        [\"G1\",3,numberOfEpochs,1000],      \n",
    "        # \n",
    "        [\"A1\",4,numberOfEpochs,1000],\n",
    "        [\"B1\",4,numberOfEpochs,1000],\n",
    "        [\"C1\",4,numberOfEpochs,1000],\n",
    "        [\"D1\",4,numberOfEpochs,1000],\n",
    "        [\"E1\",4,numberOfEpochs,1000],\n",
    "        [\"F1\",4,numberOfEpochs,1000],\n",
    "        [\"G1\",4,numberOfEpochs,1000],\n",
    "        #\n",
    "        [\"A2\",1,numberOfEpochs,1000],\n",
    "        [\"B2\",1,numberOfEpochs,1000],\n",
    "        [\"C2\",1,numberOfEpochs,1000],\n",
    "        [\"D2\",1,numberOfEpochs,1000],\n",
    "        [\"E2\",1,numberOfEpochs,1000],\n",
    "        [\"F2\",1,numberOfEpochs,1000],\n",
    "        [\"G2\",1,numberOfEpochs,1000],\n",
    "        #\n",
    "        [\"A2\",2,numberOfEpochs,1000],\n",
    "        [\"B2\",2,numberOfEpochs,1000],\n",
    "        [\"C2\",2,numberOfEpochs,1000],\n",
    "        [\"D2\",2,numberOfEpochs,1000],\n",
    "        [\"E2\",2,numberOfEpochs,1000],\n",
    "        [\"F2\",2,numberOfEpochs,1000],\n",
    "        [\"G2\",2,numberOfEpochs,1000],\n",
    "        #\n",
    "        [\"A2\",3,numberOfEpochs,1000],\n",
    "        [\"B2\",3,numberOfEpochs,1000],\n",
    "        [\"C2\",3,numberOfEpochs,1000],\n",
    "        [\"D2\",3,numberOfEpochs,1000],\n",
    "        [\"E2\",3,numberOfEpochs,1000],\n",
    "        [\"F2\",3,numberOfEpochs,1000],\n",
    "        [\"G2\",3,numberOfEpochs,1000],      \n",
    "        # \n",
    "        [\"A2\",4,numberOfEpochs,1000],\n",
    "        [\"B2\",4,numberOfEpochs,1000],\n",
    "        [\"C2\",4,numberOfEpochs,1000],\n",
    "        [\"D2\",4,numberOfEpochs,1000],\n",
    "        [\"E2\",4,numberOfEpochs,1000],\n",
    "        [\"F2\",4,numberOfEpochs,1000],\n",
    "        [\"G2\",4,numberOfEpochs,1000],\n",
    "        #\n",
    "        [\"A4\",1,numberOfEpochs,1000],\n",
    "        [\"B4\",1,numberOfEpochs,1000],\n",
    "        [\"C4\",1,numberOfEpochs,1000],\n",
    "        [\"D4\",1,numberOfEpochs,1000],\n",
    "        [\"E4\",1,numberOfEpochs,1000],\n",
    "        [\"F4\",1,numberOfEpochs,1000],\n",
    "        [\"G4\",1,numberOfEpochs,1000],\n",
    "        #\n",
    "        [\"A4\",2,numberOfEpochs,1000],\n",
    "        [\"B4\",2,numberOfEpochs,1000],\n",
    "        [\"C4\",2,numberOfEpochs,1000],\n",
    "        [\"D4\",2,numberOfEpochs,1000],\n",
    "        [\"E4\",2,numberOfEpochs,1000],\n",
    "        [\"F4\",2,numberOfEpochs,1000],\n",
    "        [\"G4\",2,numberOfEpochs,1000],\n",
    "        #\n",
    "        [\"A4\",3,numberOfEpochs,1000],\n",
    "        [\"B4\",3,numberOfEpochs,1000],\n",
    "        [\"C4\",3,numberOfEpochs,1000],\n",
    "        [\"D4\",3,numberOfEpochs,1000],\n",
    "        [\"E4\",3,numberOfEpochs,1000],\n",
    "        [\"F4\",3,numberOfEpochs,1000],\n",
    "        [\"G4\",3,numberOfEpochs,1000],      \n",
    "        # \n",
    "        [\"A4\",4,numberOfEpochs,1000],\n",
    "        [\"B4\",4,numberOfEpochs,1000],\n",
    "        [\"C4\",4,numberOfEpochs,1000],\n",
    "        [\"D4\",4,numberOfEpochs,1000],\n",
    "        [\"E4\",4,numberOfEpochs,1000],\n",
    "        [\"F4\",4,numberOfEpochs,1000],\n",
    "        [\"G4\",4,numberOfEpochs,1000],\n",
    "    ]\n",
    "\n",
    "if False:\n",
    "    list_infoNN=[\n",
    "        [\"A1\",1,numberOfEpochs,1000],\n",
    "        [\"B1\",1,numberOfEpochs,1000],\n",
    "        [\"A2\",1,numberOfEpochs,1000],\n",
    "        [\"B2\",1,numberOfEpochs,1000],\n",
    "        [\"A4\",4,numberOfEpochs,1000],\n",
    "        [\"B4\",4,numberOfEpochs,1000],\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "nparray OutputTest\n",
      "[[-1. -1. -1. ...  1. -1.  1.]\n",
      " [-1.  1. -1. ... -1. -1. -1.]\n",
      " [-1.  1.  1. ...  1.  1. -1.]\n",
      " ...\n",
      " [ 1.  1.  1. ... -1. -1. -1.]\n",
      " [ 1.  1.  1. ... -1. -1. -1.]\n",
      " [ 1.  1.  1. ... -1. -1. -1.]]\n",
      "type <class 'numpy.ndarray'> shape (14561, 20) min_value=-1.000 min_position=0 max_value=1.000 max_position=10\n",
      "nameNN l_A1_k_1_e_300_b_1000 ratio 0.646682920129112 nparray_counterLine [ 4 16  9 ... 15 14 16]\n",
      "nameNN l_B1_k_1_e_300_b_1000 ratio 0.6427992582926997 nparray_counterLine [ 6 12  7 ... 16 16 17]\n",
      "nameNN l_C1_k_1_e_300_b_1000 ratio 0.6492960648307122 nparray_counterLine [ 4 16  9 ... 15 16 17]\n",
      "nameNN l_D1_k_1_e_300_b_1000 ratio 0.6376210425108165 nparray_counterLine [ 3 15 10 ... 16 16 16]\n",
      "nameNN l_E1_k_1_e_300_b_1000 ratio 0.6377240574136391 nparray_counterLine [ 5 15 10 ... 13 13 15]\n",
      "nameNN l_F1_k_1_e_300_b_1000 ratio 0.6435306641027402 nparray_counterLine [ 4 12  7 ... 14 12 15]\n",
      "nameNN l_G1_k_1_e_300_b_1000 ratio 0.5838300940869445 nparray_counterLine [10 12  7 ...  9 10 13]\n",
      "nameNN l_A1_k_2_e_300_b_1000 ratio 0.6553842455875283 nparray_counterLine [ 4 14  7 ... 15 14 19]\n",
      "nameNN l_B1_k_2_e_300_b_1000 ratio 0.6492788956802418 nparray_counterLine [ 5 15  9 ... 15 17 16]\n",
      "nameNN l_C1_k_2_e_300_b_1000 ratio 0.6485303207197308 nparray_counterLine [ 3 14  8 ... 14 15 17]\n",
      "nameNN l_D1_k_2_e_300_b_1000 ratio 0.6507073689993819 nparray_counterLine [ 5 15  8 ... 15 16 15]\n",
      "nameNN l_E1_k_2_e_300_b_1000 ratio 0.6444200260971087 nparray_counterLine [ 5 13  8 ... 15 16 15]\n",
      "nameNN l_F1_k_2_e_300_b_1000 ratio 0.6307190440217018 nparray_counterLine [ 4 14  9 ... 12 13 16]\n",
      "nameNN l_G1_k_2_e_300_b_1000 ratio 0.5834695419270655 nparray_counterLine [11 11  6 ... 12 11 14]\n",
      "nameNN l_A1_k_3_e_300_b_1000 ratio 0.648458210287755 nparray_counterLine [ 4 16  8 ... 17 16 16]\n",
      "nameNN l_B1_k_3_e_300_b_1000 ratio 0.6558581141405123 nparray_counterLine [ 3 15  8 ... 16 15 18]\n",
      "nameNN l_C1_k_3_e_300_b_1000 ratio 0.6410651740951858 nparray_counterLine [ 6 14  7 ... 14 14 17]\n",
      "nameNN l_D1_k_3_e_300_b_1000 ratio 0.6493510061122175 nparray_counterLine [ 4 14  9 ... 13 14 16]\n",
      "nameNN l_E1_k_3_e_300_b_1000 ratio 0.6514353409793283 nparray_counterLine [ 2 15  9 ... 13 14 14]\n",
      "nameNN l_F1_k_3_e_300_b_1000 ratio 0.6229757571595358 nparray_counterLine [ 7 13  8 ... 11 12 14]\n",
      "nameNN l_G1_k_3_e_300_b_1000 ratio 0.6016688414257263 nparray_counterLine [11 11  6 ... 11 12 15]\n",
      "nameNN l_A1_k_4_e_300_b_1000 ratio 0.6417828445848499 nparray_counterLine [ 4 14  9 ... 17 15 17]\n",
      "nameNN l_B1_k_4_e_300_b_1000 ratio 0.6538012499141542 nparray_counterLine [ 5 15  8 ... 16 17 14]\n",
      "nameNN l_C1_k_4_e_300_b_1000 ratio 0.6463223679692329 nparray_counterLine [ 5 15 10 ... 14 15 15]\n",
      "nameNN l_D1_k_4_e_300_b_1000 ratio 0.6468958175949454 nparray_counterLine [ 6 12  6 ... 16 16 16]\n",
      "nameNN l_E1_k_4_e_300_b_1000 ratio 0.6411613213378202 nparray_counterLine [ 6 12  7 ... 16 15 16]\n",
      "nameNN l_F1_k_4_e_300_b_1000 ratio 0.6269040587871713 nparray_counterLine [ 7 12  6 ... 12 12 15]\n",
      "nameNN l_G1_k_4_e_300_b_1000 ratio 0.6011297301009546 nparray_counterLine [11 11  6 ... 11 12 15]\n",
      "nameNN l_A2_k_1_e_300_b_1000 ratio 0.6493922120733466 nparray_counterLine [ 3 15 10 ... 16 16 18]\n",
      "nameNN l_B2_k_1_e_300_b_1000 ratio 0.6520671657166404 nparray_counterLine [ 3 15  9 ... 14 14 16]\n",
      "nameNN l_C2_k_1_e_300_b_1000 ratio 0.6442380331021221 nparray_counterLine [ 5 15  8 ... 14 15 15]\n",
      "nameNN l_D2_k_1_e_300_b_1000 ratio 0.6483277247441797 nparray_counterLine [ 3 15  8 ... 13 15 17]\n",
      "nameNN l_E2_k_1_e_300_b_1000 ratio 0.6485200192294486 nparray_counterLine [ 5 15 10 ... 15 16 17]\n",
      "nameNN l_F2_k_1_e_300_b_1000 ratio 0.642933177666369 nparray_counterLine [ 2 16  9 ... 15 15 16]\n",
      "nameNN l_G2_k_1_e_300_b_1000 ratio 0.5948526886889637 nparray_counterLine [10 12  7 ... 12 13 16]\n",
      "nameNN l_A2_k_2_e_300_b_1000 ratio 0.6669871574754481 nparray_counterLine [ 2 16  9 ... 16 17 17]\n",
      "nameNN l_B2_k_2_e_300_b_1000 ratio 0.6182748437607307 nparray_counterLine [ 1 15 10 ... 15 16 16]\n",
      "nameNN l_C2_k_2_e_300_b_1000 ratio 0.6568676601881739 nparray_counterLine [ 4 16  9 ... 15 16 17]\n",
      "nameNN l_D2_k_2_e_300_b_1000 ratio 0.6479877755648651 nparray_counterLine [ 5 15  8 ... 13 16 17]\n",
      "nameNN l_E2_k_2_e_300_b_1000 ratio 0.6442826728933453 nparray_counterLine [ 5 13  8 ... 13 14 17]\n",
      "nameNN l_F2_k_2_e_300_b_1000 ratio 0.6236934276491999 nparray_counterLine [ 9 13  8 ... 14 14 16]\n",
      "nameNN l_G2_k_2_e_300_b_1000 ratio 0.601740951857702 nparray_counterLine [11 11  6 ... 11 12 15]\n",
      "nameNN l_A2_k_3_e_300_b_1000 ratio 0.6503056108783737 nparray_counterLine [ 5 15  8 ... 16 17 17]\n",
      "nameNN l_B2_k_3_e_300_b_1000 ratio 0.6434997596318934 nparray_counterLine [ 5 13  6 ... 15 14 13]\n",
      "nameNN l_C2_k_3_e_300_b_1000 ratio 0.6368724675503056 nparray_counterLine [ 5 15  8 ... 14 14 17]\n",
      "nameNN l_D2_k_3_e_300_b_1000 ratio 0.6476890323466795 nparray_counterLine [ 5 13  6 ... 15 17 14]\n",
      "nameNN l_E2_k_3_e_300_b_1000 ratio 0.6470469061190852 nparray_counterLine [ 4 16  9 ... 11 13 16]\n",
      "nameNN l_F2_k_3_e_300_b_1000 ratio 0.6131584369205412 nparray_counterLine [ 8 10  7 ... 11 12 15]\n",
      "nameNN l_G2_k_3_e_300_b_1000 ratio 0.6017512533479843 nparray_counterLine [11 11  6 ... 11 12 15]\n",
      "nameNN l_A2_k_4_e_300_b_1000 ratio 0.6415184396676052 nparray_counterLine [ 5 12  7 ... 14 15 15]\n",
      "nameNN l_B2_k_4_e_300_b_1000 ratio 0.6551370098207541 nparray_counterLine [ 3 15  9 ... 16 15 17]\n",
      "nameNN l_C2_k_4_e_300_b_1000 ratio 0.6520053567749468 nparray_counterLine [ 4 16  9 ... 14 15 16]\n",
      "nameNN l_D2_k_4_e_300_b_1000 ratio 0.6464322505322436 nparray_counterLine [ 3 16  9 ... 15 16 15]\n",
      "nameNN l_E2_k_4_e_300_b_1000 ratio 0.6325904814229792 nparray_counterLine [ 7 13  8 ... 13 13 16]\n",
      "nameNN l_F2_k_4_e_300_b_1000 ratio 0.6116853238101779 nparray_counterLine [ 8 14  5 ... 11 12 15]\n",
      "nameNN l_G2_k_4_e_300_b_1000 ratio 0.601778723988737 nparray_counterLine [11 11  6 ... 11 12 15]\n",
      "nameNN l_A4_k_1_e_300_b_1000 ratio 0.634637044159055 nparray_counterLine [ 5 13  6 ... 14 15 16]\n",
      "nameNN l_B4_k_1_e_300_b_1000 ratio 0.6485852620012362 nparray_counterLine [ 5 17  8 ... 15 16 18]\n",
      "nameNN l_C4_k_1_e_300_b_1000 ratio 0.6517272165373257 nparray_counterLine [ 3 15  8 ... 16 16 15]\n",
      "nameNN l_D4_k_1_e_300_b_1000 ratio 0.6032999107204176 nparray_counterLine [ 6 12  7 ... 11 14 12]\n",
      "nameNN l_E4_k_1_e_300_b_1000 ratio 0.6418892933177667 nparray_counterLine [ 5 17 10 ... 13 14 14]\n",
      "nameNN l_F4_k_1_e_300_b_1000 ratio 0.5898152599409381 nparray_counterLine [ 7 11  8 ... 12 11 13]\n",
      "nameNN l_G4_k_1_e_300_b_1000 ratio 0.5956218666300391 nparray_counterLine [10 10  5 ... 11 12 15]\n",
      "nameNN l_A4_k_2_e_300_b_1000 ratio 0.644351349495227 nparray_counterLine [ 6 16  8 ... 14 15 15]\n",
      "nameNN l_B4_k_2_e_300_b_1000 ratio 0.6411304168669735 nparray_counterLine [ 7 13  8 ... 14 16 16]\n",
      "nameNN l_C4_k_2_e_300_b_1000 ratio 0.6492788956802418 nparray_counterLine [ 3 17 10 ... 15 16 17]\n",
      "nameNN l_D4_k_2_e_300_b_1000 ratio 0.6426275667879954 nparray_counterLine [ 4 16  9 ... 15 16 16]\n",
      "nameNN l_E4_k_2_e_300_b_1000 ratio 0.6306778380605728 nparray_counterLine [ 4 14  9 ... 14 14 16]\n",
      "nameNN l_F4_k_2_e_300_b_1000 ratio 0.6194045738616853 nparray_counterLine [ 6 14 10 ... 13 13 16]\n",
      "nameNN l_G4_k_2_e_300_b_1000 ratio 0.5918858594876726 nparray_counterLine [12 12  7 ... 10 13 14]\n",
      "nameNN l_A4_k_3_e_300_b_1000 ratio 0.6619050889361995 nparray_counterLine [ 2 16 11 ... 14 16 15]\n",
      "nameNN l_B4_k_3_e_300_b_1000 ratio 0.6218219902479225 nparray_counterLine [ 5 15 12 ... 14 15 16]\n",
      "nameNN l_C4_k_3_e_300_b_1000 ratio 0.6434894581416112 nparray_counterLine [ 3 15 10 ... 14 15 13]\n",
      "nameNN l_D4_k_3_e_300_b_1000 ratio 0.6264439255545635 nparray_counterLine [ 5 13  8 ... 15 16 17]\n",
      "nameNN l_E4_k_3_e_300_b_1000 ratio 0.6495089622965455 nparray_counterLine [ 2 14  9 ... 15 16 17]\n",
      "nameNN l_F4_k_3_e_300_b_1000 ratio 0.6343142641302109 nparray_counterLine [ 6 14  7 ... 12 13 14]\n",
      "nameNN l_G4_k_3_e_300_b_1000 ratio 0.5882459995879404 nparray_counterLine [10 12  9 ...  8 11 12]\n",
      "nameNN l_A4_k_4_e_300_b_1000 ratio 0.6223404985921297 nparray_counterLine [ 7 11  6 ... 17 14 17]\n",
      "nameNN l_B4_k_4_e_300_b_1000 ratio 0.6479671725843005 nparray_counterLine [ 4 16  9 ... 13 13 15]\n",
      "nameNN l_C4_k_4_e_300_b_1000 ratio 0.6029462262207266 nparray_counterLine [ 8 14  7 ... 14 15 15]\n",
      "nameNN l_D4_k_4_e_300_b_1000 ratio 0.6578050958038596 nparray_counterLine [ 2 14  9 ... 17 15 16]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nameNN l_E4_k_4_e_300_b_1000 ratio 0.5665716640340636 nparray_counterLine [ 7 11  8 ... 14 14 10]\n",
      "nameNN l_F4_k_4_e_300_b_1000 ratio 0.6418961609779548 nparray_counterLine [ 4 16  9 ... 15 15 16]\n",
      "nameNN l_G4_k_4_e_300_b_1000 ratio 0.5621523247029737 nparray_counterLine [11 11  8 ... 11 12 17]\n"
     ]
    }
   ],
   "source": [
    "if doAnalyzeNN:\n",
    "    dict_io_tt_nparray=read_from_file_NN_data_dict_io_tt_nparray()\n",
    "    nparray_input=dict_io_tt_nparray[\"Input\"+\"Test\"]\n",
    "    nparray_output=dict_io_tt_nparray[\"Output\"+\"Test\"]\n",
    "    print_nparray(\"Output\"+\"Test\",nparray_output,True)\n",
    "    # loop over different NN that we compare (arhitecture and learning)\n",
    "    list_tupleArray=[]\n",
    "    for infoNN in list_infoNN:\n",
    "        nameNN,layer,k,nrEpoch,batchSize=get_from_infoNN(infoNN)\n",
    "        if False:\n",
    "            print(\"nameNN\",nameNN)\n",
    "        # create empty train model architecture (layer and k), with bad initial random weights\n",
    "        model=prepare_NN_model(layer,k)\n",
    "        fileNameWeights=get_fileNameWeights(nameNN)\n",
    "        model.load_weights(fileNameWeights)\n",
    "        nparray_outputPredicted=model.predict(nparray_input)\n",
    "        nparray_outputDiff=nparray_outputPredicted-nparray_output\n",
    "        print_nparray(\"OutputPredicted\"+\"Test\",nparray_outputPredicted,False)\n",
    "        print_nparray(\"OutputDiff\"+\"Test\",nparray_outputDiff,False)\n",
    "        counterTotal=0\n",
    "        list_counterLine=[]\n",
    "        for line in nparray_outputDiff:\n",
    "            counterLine=0\n",
    "            for el in line:\n",
    "                if el==0:\n",
    "                    counterLine+=1\n",
    "                    counterTotal+=1\n",
    "            # done loop over el in line\n",
    "            list_counterLine.append(counterLine)\n",
    "            # print(el)\n",
    "        # done loop over all lines\n",
    "        nrEl=nparray_outputDiff.shape[0]*nparray_outputDiff.shape[1]\n",
    "        ratio=counterTotal/nrEl\n",
    "        # print(\"ratio\",ratio)\n",
    "        # convert list_counterLine to a numpy array, so that we can plot it as a histogram\n",
    "        nparray_counterLine=np.array(list_counterLine)\n",
    "        # print_nparray(\"nparray_counterLine\",nparray_counterLine,False)\n",
    "        print(\"nameNN\",nameNN,\"ratio\",ratio,\"nparray_counterLine\",nparray_counterLine)\n",
    "        list_tupleArray.append((nparray_counterLine,nameNN))\n",
    "    # done loop over all NNs\n",
    "    # make the plot that overlays several NNs\n",
    "    if False:\n",
    "        overlay_histogram_from_nparray_with_ratio(list_tupleArray,\n",
    "                                                  outputFileName=outputFolderName+\"/output_histo_from_nparray\",\n",
    "                                                  extensions=\"pdf\", #\"png,pdf\",\n",
    "                                                  nrBins=range(bucketSize+1),\n",
    "                                                  histtype=\"step\",\n",
    "                                                  info_x=[\"Number of correct hit matches\"],\n",
    "                                                  info_y=[\"Number of buckets\"],\n",
    "                                                  title=\"Title\",\n",
    "                                                  text=None,\n",
    "                                                  info_legend=[\"upper left\"],\n",
    "                                                  list_color=\"r,g,b,k,y,magenta\".split(\",\"),\n",
    "                                                  doAddRatioPad=False,\n",
    "                                                  debug=False,\n",
    "                                                  verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
